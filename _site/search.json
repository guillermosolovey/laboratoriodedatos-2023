[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Laboratorio de Datos",
    "section": "",
    "text": "Profesor: Guillermo Solovey.\nAyudantes: Dario Elías y Yamila Alen.\nHorario: Viernes de 10 a 13 y de 14 a 17.\nClases: desde el 18 de Agosto al 1 de Diciembre.\nLaboratorio: 1103.\n\n\n\n Exactas-UBA\n\n\n Licenciatura en Ciencia de Datos"
  },
  {
    "objectID": "cronograma.html",
    "href": "cronograma.html",
    "title": "Cronograma",
    "section": "",
    "text": "fecha\ntema\nslides\nguias\ntp\n\n\n\n\n18/8\nIntroducción a la materia. Ciencia de datos. Tipos de preguntas. Introducción a R y RStudio | Charla Dátame.\n\n\n\n\n\n25/8\nEstadística descriptiva. Visualización. Gramática de gráficos.\n\n\n\n\n\n1/9\nAnálisis exploratorio de datos y comunicación.\n\n\n\n\n\n8/9\nTransformación de datos: datos ordenados, vectores, data frames. Unión de data frames.\n\n\n\n\n\n15/9\nProgramación en R: funciones, iteraciones | Charla Dátame.\n\n\n\n\n\n22/9\nReproducibilidad computacional. Comunicación e informes con RMarkdown/Quarto.\n\n\nPresentación TP1\n\n\n29/9\nIntroducción al modelado. Modelos supervisados y no supervisados. Regresión vs. clasificación. Trade-off sesgo-varianza. Modelo de regresión lineal simple.\n\n\nConsultas TP1\n\n\n6/10\nRegresión: regresión lineal múltiple y K-nearest neighbors.\n\n\nEnvío TP1 (límite: 5 de Oct, 23:59)\n\n\n13/10\nFeriado\n\n\n\n\n\n20/10\nClasificación: Árboles de decisión y K-nearest neighbors | Charla Dátame.\n\n\nDevolución TP1\n\n\n27/10\nHerramientas de validación de un modelo. Métodos de resampleo. Muestras de testeo y entrenamiento.Métricas\n\n\nPresentación TP2\n\n\n3/11\nAprendizaje no supervisado. Métodos de clustering: K-means y clustering jerárquico.\n\n\nConsultas TP2\n\n\n10/11\nConsultas.\n\n\nEnvío TP2 (límite: 9 de Nov, 23:59)\n\n\n17/11\nParcial de 10 a 13hs en aula a confirmar | Charla Dátame.\n\n\n\n\n\n24/11\nEntrega de notas del parcial y TP2. Cierre\n\n\n\n\n\n1/12\nRecuperatorio del parcial, de 10 a 13hs en aula a confirmar.\n\n\nRe-entrega de TPs.\n\n\n8/12\nEntrega de notas del recuperatorio y de los TPs. Cierre."
  },
  {
    "objectID": "index.html#course-materials",
    "href": "index.html#course-materials",
    "title": "Estimación Bayesiana",
    "section": "Course materials",
    "text": "Course materials\n\nBooks\nWe’ll be working through two textbooks throughout the semester:\n\nRichard McElreath, Statistical Rethinking: A Bayesian Course with Examples in R and Stan\n\n\n\n\nAlicia A. Johnson, Miles Q. Ott, and Mine Dogucu, Bayes Rules! An Introduction to Applied Bayesian Modeling\n\n\n\nBayes Rules! is available online for free. The book for Statistical Rethinking is not free ($70 on Amazon), but Richard McElreath has provided 20 video lectures with accompanying slides and homework assignments and answer keys.\nWe’ll read all of Bayes Rules!, all of Statistical Rethinking, watch all of McElreath’s Statistical Rethinking lectures, and complete a bunch of the assignments and homework questions from both books.\n\nDocente\n\nDocente: Dr. Guillermo Solovey\nOficina: 2605, Edificio Cero+Infinito, Exactas-UBA\n\n\n\nFechas\n\nInscripción: Primer cuatrimestre 2023. Inicio de clases: semana del 20 de Marzo.\nDictado: Primer cuatrimestre 2023. Inicio de clases: semana del 20 de Marzo.\nHorarios: 4 horas semanales en días y horario a definir.\n\n\n\nCorrelativas\n\nIntroducción a la Estadística y la Ciencia de Datos.\n\n\n\nCódigo de inscripción en el SIU\n\nGrado: a definir\nDoctorado: a definir\n\n\n\nBibliografía\n\nVamos a usar principalmente Bayes Rules! y Statistical Rethinking.\n\n\n\n Instituto de Cálculo\n\n\n Facultad de Ciencias Exactas y Naturales, UBA"
  },
  {
    "objectID": "programa.html",
    "href": "programa.html",
    "title": "Programa",
    "section": "",
    "text": "próximamente…"
  },
  {
    "objectID": "programa.html#bibliografía",
    "href": "programa.html#bibliografía",
    "title": "Programa",
    "section": "Bibliografía",
    "text": "Bibliografía\nprincipal:\n\nAlicia A. Johnson, Miles Q. Ott, and Mine Dogucu, Bayes Rules! An Introduction to Applied Bayesian Modeling\nRichard McElreath, Statistical Rethinking: A Bayesian Course with Examples in R and Stan, 2nd edition.\n\n\ncomplementaria:\n\nBen Lambert, A Student’s Guide to Bayesian Statistics.\nOsvaldo A. Martin, Ravin Kumar y Junpeng Lao, Bayesian Modeling and Computation in Python.\nPeter D. Hoff, A first course in Bayesian statistical methods.\nCameron Davidson-Pilon, Bayesian methods for hackers: probabilistic programming and Bayesian inference.\nDavid Robinson, Introduction to empirical bayes: examples from baseball statistics.\nAndrew Gelman, Jennifer Hill, and Aki Vehtari, Regression and other stories."
  },
  {
    "objectID": "programa.html#programa",
    "href": "programa.html#programa",
    "title": "Programa",
    "section": "Programa",
    "text": "Programa\n\nUnidad 1\nFundamentos bayesianos: Aprender cómo pensar bayesianamente y cómo crear modelos bayesianos básicos.\nIntroducción a la estadística bayesiana. Diferencias entre estadística bayesiana y frecuentista. Pensar bayesianamente. Modelo beta-binomial. Equilibrio entre el prior y los datos. Análisis bayesiano secuencial. Familias conjugadas.\n\n\nUnidad 2\nSimulación y análisis de la distribución posterior: Herramientas computacionales para simular la distribución posterior en modelos bayesianos complejos.\nAnalizar modelos simulados y exactos para hacer inferencia y sacar conclusiones. Aproximar la distribución posterior. Método de grilla, Metrópolis-Hastings y Markov Chain Monte Carlo (MCMC). Implementación y diagnóstico en R. Estimación de parámetros Testeo de hipótesis. Predicción.\n\n\nUnidad 3\nModelos bayesianos de regresión y clasificación: Extender los modelos bayesianos a casos en los que la variable respuesta es contínua (regresión) y categórica (clasificación).\nRegresión Normal. Regresión múltiple. Variables de control y confusoras. Evaluación, diagnóstico y comparación de modelos de regresión. Regresión de Poisson. Naive-Bayes. Regresión logística.\n\n\nUnidad 4\nModelos bayesianos jerárquicos: Modelos bayesianos para datos multi-nivel, como datos longitudinales y de medidas repetidas.\nModelo complete-pool y no-pool. Modelos de pooling parcial. Modelo jerárquico normal sin predictores. Modelos de regresión y clasificación jerárquicos."
  },
  {
    "objectID": "index.html#docente",
    "href": "index.html#docente",
    "title": "Estimación Bayesiana",
    "section": "Docente",
    "text": "Docente\n\nDocente: Dr. Guillermo Solovey\nOficina: 2605, Edificio Cero+Infinito, Exactas-UBA"
  },
  {
    "objectID": "index.html#fechas",
    "href": "index.html#fechas",
    "title": "Estimación Bayesiana",
    "section": "Fechas",
    "text": "Fechas\n\nInscripción: desde el 22 de Febrero al 5 de Marzo de 2023.\nDictado: Primer cuatrimestre 2023. Inicio de clases: semana del 20 de Marzo.\nHorarios: 4 horas semanales en días y horario a definir."
  },
  {
    "objectID": "index.html#correlativas",
    "href": "index.html#correlativas",
    "title": "Estimación Bayesiana",
    "section": "Correlativas",
    "text": "Correlativas\n\nIntroducción a la Estadística y la Ciencia de Datos.\n\n\n\n Instituto de Cálculo\n\n\n Facultad de Ciencias Exactas y Naturales, UBA"
  },
  {
    "objectID": "index.html#código-de-inscripción-en-el-siu",
    "href": "index.html#código-de-inscripción-en-el-siu",
    "title": "Estimación Bayesiana",
    "section": "Código de inscripción en el SIU",
    "text": "Código de inscripción en el SIU\n\nGrado: a definir\nDoctorado: a definir"
  },
  {
    "objectID": "index.html#bibliografía",
    "href": "index.html#bibliografía",
    "title": "Estimación Bayesiana",
    "section": "Bibliografía",
    "text": "Bibliografía\n\n?var:course.text\n\n\n\n Instituto de Cálculo\n\n\n Facultad de Ciencias Exactas y Naturales, UBA"
  },
  {
    "objectID": "programa.html#régimen-de-aprobación",
    "href": "programa.html#régimen-de-aprobación",
    "title": "Programa",
    "section": "Régimen de aprobación",
    "text": "Régimen de aprobación\nLa materia tiene 4 entregas. La nota final de la materia se compone así - 1a entrega: 20% - 2a entrega: 20% - 3a entrega: 20% - 4a entrega: 40%"
  },
  {
    "objectID": "programa.html#entregas",
    "href": "programa.html#entregas",
    "title": "Programa",
    "section": "Entregas",
    "text": "Entregas\nCada entrega tiene una fecha límite que es dos semanas después de la clase (ver cronograma). No aceptamos entregas sin aviso después de ese día. Antes de la fecha límite se puede pedir una prórroga de 1 semana, pero eso sólo se puede hacer 1 vez en todo el curso. Las entregas: sin código y cómo enviar entregas: G1-E1-APELLIDO-NOMBRE.PDF"
  },
  {
    "objectID": "programa.html#trabajo-final",
    "href": "programa.html#trabajo-final",
    "title": "Programa",
    "section": "Trabajo final",
    "text": "Trabajo final\nLa última entrega consiste de un trabajo final…"
  },
  {
    "objectID": "pautas.html",
    "href": "pautas.html",
    "title": "Pautas",
    "section": "",
    "text": "El trabajo a lo largo de este curso consiste en elegir un conjunto de datos, realizar un análisis adecuado del mismo utilizando al menos dos técnicas aprendidas durante la carrera de especialización y redactar un informe final."
  },
  {
    "objectID": "pautas.html#organización",
    "href": "pautas.html#organización",
    "title": "Pautas",
    "section": "Organización",
    "text": "Organización\nEl curso está dividido en 4 grupos. Cada grupo asiste a una clase presencial por mes los días martes a las 19.30 horas. Durante las clases presenciales Guillermo Solovey y Gustavo Juantorena explicarán las pautas de los trabajos prácticos a entregar durante el curso y ayudarán a cada uno a conseguir el objetivo. El resto de la semana y para aquellos que no asistan presencial ese día, Jazmín Vidal responderá consultas de forma asincrónica. La presencialidad NO es opcional.\nLas consultas se realizan escribiendo a tallerdetesis1-2023@googlegroups.com. Pueden consultar el cronograma de asistencia por grupo acá."
  },
  {
    "objectID": "pautas.html#régimen-de-aprobación",
    "href": "pautas.html#régimen-de-aprobación",
    "title": "Pautas",
    "section": "Régimen de aprobación",
    "text": "Régimen de aprobación\nLa materia tiene 4 entregas (3 entregas parciales y un trabajo final) y se aprueba con 65 puntos. La nota final de la materia se compone así:\n\nEntrega 1: 20 puntos\nEntrega 2: 20 puntos\nEntrega 3: 20 puntos\nTrabajo final: 40 puntos\n\nLas consignas para las entregas y del trabajo final se explican los días martes en la clase presencial de cada grupo. Cada entrega tiene una fecha límite que es dos semanas después de la clase. Tener en cuenta que las entregas son incrementales, esto es, que cada una depende de la anterior y culmina en el trabajo final.\nEn caso de entregar con retraso, el trabajo tendrá una puntuación menor. Los trabajos entregados hasta una semana después de la fecha límite tendrán 5 puntos menos de puntaje máximo. Los trabajos entregados con más de una semana de atraso tendrán 10 puntos menos de nota máxima.\nLas entregas se cargan en una carpeta de google drive. Hay una carpeta para cada entrega y para cada grupo. Las entregas deben enviarse en PDF, sin código adjunto y con el nombre: G1-E1-APELLIDO-NOMBRE.PDF\nPueden consultar el cronograma de entregas acá."
  },
  {
    "objectID": "pautas.html#uso-de-datos",
    "href": "pautas.html#uso-de-datos",
    "title": "Pautas",
    "section": "Uso de datos",
    "text": "Uso de datos\nPueden encontrar pautas generales para la elección del dataset en este documento. En general, pueden utilizar:\n\nDatos públicos: sugerimos la utilización de uno de los datasets provistos en la siguiente lista. Si el dataset es muy popular y ya hay en internet muchos trabajos hechos, se deberá reportar cómo el trabajo a realizar difiere de ellos.\nDatos propios: si se deseara realizar las entregas y el informe final utilizando un conjunto de datos propio, se deberá contar -ANTES DE LA PRIMERA ENTREGA- con autorización para hacerlo. De lo contrario tendrán que utilizar un conjunto de datos públicos como los sugeridos en el ítem anterior.\nDatos scrapeados: datos visibles en una web no necesariamente significa que los podemos scrapear para los fines de este trabajo. Cada página tiene sus condiciones de uso de datos. Sólo se pueden scrapear los datos si está permitido hacerlo."
  },
  {
    "objectID": "pautas.html#otros-recursos",
    "href": "pautas.html#otros-recursos",
    "title": "Pautas",
    "section": "Otros recursos",
    "text": "Otros recursos\nEjemplos de trabajos de años anteriores\n\nDetección de cataratas y glaucoma en imágenes de fondo de ojo. Hernán Estrin\nPatrones de uso del servicio de datos en la red de telefonía móvil de la ciudad de Milán. Horacio Gastón Arrigo"
  },
  {
    "objectID": "pautas.html#preguntas-frecuentes",
    "href": "pautas.html#preguntas-frecuentes",
    "title": "Pautas",
    "section": "Preguntas frecuentes",
    "text": "Preguntas frecuentes\n\n¿Qué diferencia hay entre el trabajo de especialización y el trabajo final de esta materia?\nPoco. Si cumplen con los objetivos de esta materia y hacen todas las entregas de forma completa, van a estar a un paso del trabajo de especialización. Podrían quedar algunas cositas por pulir, pero nada que les impide entregarlo pocas semanas después de finalizada la materia.\n¿Quién evalúa el trabajo de especialización?\nEn esta materia, los docentes no evaluamos los trabajos finales de especialización pero los preparamos para entregarlo. El trabajo de especialización lo evalúan docentes del posgrado.\n¿Qué diferencia hay entre el trabajo de especialización y la tesis de maestría?\nEl trabajo de tesis de maestría requiere director/a, se espera que sea más extenso que el de especialización.\n¿Es requisito hacer el trabajo de especialización si quiero seguir con la maestría?\nNo. Se puede aprobar esta materia con todos sus requisitos y continuar hacia la maestría.\n¿Necesito tutor/director para hacer el trabajo de especialización?\nNo.\n¿En qué formato hay que escribir el trabajo final?\nEl que les resulte más cómodo. Puede ser overleaf, Rmd, google docs, Word, … pero el entregable tiene que estar en pdf."
  },
  {
    "objectID": "pautas.html#chat-gpt",
    "href": "pautas.html#chat-gpt",
    "title": "Pautas",
    "section": "Chat GPT",
    "text": "Chat GPT\nLe preguntamos a Chat GPT como realizar un uso creativo del mismo a lo largo del curso y, entre otras cosas, lo que nos dijo fue:\n\n\n\n\n\n\nImportante!\n\n\n\nRecuerda que, aunque Chat GPT puede ser una herramienta útil para ayudarte en tu trabajo final de ciencia de datos, es importante que tú mismo/a te asegures de la calidad de la información y de los resultados obtenidos. ¡Buena suerte en tu proyecto!"
  },
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "Como sugerencia general, elijan un dataset sobre un tema que les interese o sobre el que están trabajando actualmente. Como algunos conjuntos de datos se han usado en exceso para estos objetivos particulares, tenga en cuenta que los siguientes están prohibidos en este trabajo (se pueden agregar más a esta lista, así que asegúrense de revisarla regularmente):\n\ntitanic\nmtcars\niris\nMNIST\nCIFAR-10\n\nLo mejor es usar un conjunto de datos para el cual no haya un análisis listo en Internet, pero si eligen un conjunto de datos que ya se usó en algún estudio de caso disponible online, proporcionen el enlace a estudios anteriores e informen cómo sus análisis difieren de esos (por ejemplo, si alguien ha realizado un análisis no bayesiano y ustedes realizan el análisis bayesiano completo).\nSegún el modelo y la estructura de los datos, un buen dataset tendría más de 100 observaciones pero menos de 1 millón. Si conocen un dataset interesante pero muy pesado, pueden usar un subconjunto más pequeño de los datos para mantener factibles los tiempos de cálculo."
  },
  {
    "objectID": "datasets.html#inspiración",
    "href": "datasets.html#inspiración",
    "title": "Datasets",
    "section": "Inspiración",
    "text": "Inspiración\nSi están buscando inspiración o no están seguros de por dónde empezar, pueden mirar las siguientes páginas:\n\nhttps://datasetsearch.research.google.com/\nhttps://www.kaggle.com/datasets\nhttps://github.com/rfordatascience/tidytuesday\nhttps://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research\nhttps://paperswithcode.com/datasets\nhttps://www.openml.org/search?type=data&sort=runs&status=active"
  },
  {
    "objectID": "datasets.html#dónde-encontrar-papers",
    "href": "datasets.html#dónde-encontrar-papers",
    "title": "Datasets",
    "section": "¿Dónde encontrar papers?",
    "text": "¿Dónde encontrar papers?\n\nhttps://scholar.google.com/\nhttps://pubmed.ncbi.nlm.nih.gov/\nhttps://ieeexplore.ieee.org/Xplore/home.jsp"
  },
  {
    "objectID": "datasets.html#ejemplos-de-datasets",
    "href": "datasets.html#ejemplos-de-datasets",
    "title": "Datasets",
    "section": "Ejemplos de datasets",
    "text": "Ejemplos de datasets\nAlgunos ejemplos específicos que pueden usar según la técnica de análisis están en el siguiente documento."
  },
  {
    "objectID": "consignas.html",
    "href": "consignas.html",
    "title": "Consignas",
    "section": "",
    "text": "Para ver el cronograma de entregas, ver acá."
  },
  {
    "objectID": "consignas.html#entrega-1-dataset-pregunta-y-objetivo",
    "href": "consignas.html#entrega-1-dataset-pregunta-y-objetivo",
    "title": "Consignas",
    "section": "Entrega 1: Dataset, pregunta y objetivo",
    "text": "Entrega 1: Dataset, pregunta y objetivo\nConsigna para la entrega 1."
  },
  {
    "objectID": "consignas.html#entrega-2-metodología-y-análisis-exploratorio-de-datos",
    "href": "consignas.html#entrega-2-metodología-y-análisis-exploratorio-de-datos",
    "title": "Consignas",
    "section": "Entrega 2: Metodología y análisis exploratorio de datos",
    "text": "Entrega 2: Metodología y análisis exploratorio de datos\nConsigna para la entrega 2."
  },
  {
    "objectID": "consignas.html#entrega-3-introducción-y-resultados",
    "href": "consignas.html#entrega-3-introducción-y-resultados",
    "title": "Consignas",
    "section": "Entrega 3: Introducción y resultados",
    "text": "Entrega 3: Introducción y resultados\nConsigna para la entrega 3."
  },
  {
    "objectID": "consignas.html#trabajo-final",
    "href": "consignas.html#trabajo-final",
    "title": "Consignas",
    "section": "Trabajo final",
    "text": "Trabajo final\nLa última entrega consiste en sumarle “Discusión y conclusiones” a lo hecho en las entregas anteriores, lo que constituye el trabajo final de la materia.\nConsigna para el trabajo final."
  },
  {
    "objectID": "tps.html",
    "href": "tps.html",
    "title": "Trabajos Prácticos",
    "section": "",
    "text": "Próximamente…"
  },
  {
    "objectID": "slides.html",
    "href": "slides.html",
    "title": "Slides",
    "section": "",
    "text": "clase 1 - 18/8\nclase 2 - 25/8\nclase Regresión"
  },
  {
    "objectID": "TPs/TP1.html",
    "href": "TPs/TP1.html",
    "title": "Trabajo Práctico 1",
    "section": "",
    "text": "El objetivo de estos ejercicios es reconocer, crear y hacer operaciones simples con los 5 tipos de objetos básicos de R:\n\ncharacter\nnumeric (números reales)\ninteger\ncomplex\nlogical (True/False)\n\nTambién familiarizarse con la consola de R, con matrices y con operaciones lógicas.\n1.1 Realizar las siguientes operaciones básicas en la consola\n\n2+2\na <- 2\nb <- 5\na**3\n16 %% 5 (probar con otros números para entender qué significa)\n2*a**2+0.5*b+(a+b)/2\nasignar el resultado anterior a la variable c\nimprimir el contenido de c en la consola (corriendo c o print(c)). ¿Ven un [1] delante del valor de c? Esto indica que es un vector.\n\n1.2 Interpretar las siguientes operaciones lógicas y predecir el resultado antes de probar en la consola.\n\na <- TRUE\nb <- FALSE\na == b\na || b\na == !b\n\n1.3. Antes de probar en la consola, piense que van a dar estas operaciones:\n\na <- 3\nb <- 4\na > b\na <= b\na != b\nx <- 2\n(x > a) && (10*x>b) || !(b/a>x)\n\n1.4 Los vectores en R se crean con la función c(). Por ejemplo c(2,-1) es un vector de clase numeric que tiene dos elementos, el 2 y el -1. Se puede comprobar usando la función class() así: class(c(2,-1)). Crear 5 vectores de 2 componentes de las siguiente clases básicas: character, numeric, integer, complex y logical (True/False).\n1.5. ¿Qué sucede cuando se realizan las siguientes operaciones que mezclan variables de distinta clase? ¿Por qué les parece que pasa? (usar class() para investigar el tipo de dato de los objetos)\n\nnum_char <- c(1, 2, 3, \"a\")\nnum_logical <- c(1, 2, 3, TRUE)\nchar_logical <- c(\"a\", \"b\", \"c\", TRUE)\ntramposo <- c(1, 2, 3, \"4\")\n\n1.6. Realizar las siguientes operaciones en la consola, ver el output de cada operación y escribir una frase explicando qué hace cada una.\n\nalturas_cm <- c(180, 178, 154, 202)\nfrutas <- c(\"banana\", \"pera\", \"durazno\")\nlength(alturas_cm)\nlength(frutas)\nfrutas <- c(frutas, \"uva\")\nfrutas <- c(\"naranja\", frutas)\nbajitos <- (alturas_cm < 165)\nclass(bajitos)\n1:10\n21:30\n\n1.7. Explorar estas distintas formas de extraer información del vector c(\"banana\", \"pera\", \"durazno\", \"anana\"). Primero crear el vector en la consola y asignarlo al vector frutas. Luego correr cada caso en la consola y explicar en pocas palabras qué es lo que sucede.\n\nfrutas[2]\nfrutas[c(1,4)]\nfrutas[c(1,4,1,1,2)]\nfrutas %in% c(\"ciruela\", \"frutilla\", \"pera\", \"mandarina\")\nfrutas[ frutas %in% c(\"ciruela\", \"frutilla\", \"pera\", \"mandarina\") ]\n\n1.8. ¿Por qué da error la línea 4 de esta secuencia?\n\ndatos <- c(\"banana\", 2, \"pera\", 5, \"durazno\", 0)\ndatos[2] \ndatos[4]\ndatos[2] + datos[4]\n\n1.9. Explorar distintas formas de extraer información del vector alturas_cm definido en el ejercicio 1.6. Escribir una frase explicando qué hace cada una. ¿Por qué la última retorna numeric(0)?\n\nalturas_cm[c(TRUE, FALSE, TRUE, TRUE)]\nalturas_cm[alturas_cm >= 180]\nalturas_cm[alturas_cm >= 180 & alturas_cm < 200]\nalturas_cm[alturas_cm >= 160 & alturas_cm == 195]\n\n1.10. Las matrices en R son vectores con estructura en 2D. Por ejemplo, se pueden crear de esta forma\n\nm <- matrix(1:6, nrow = 2, ncol = 3)\n\nUsar dim(m) para averiguar el atributo “dimesión” (número de filas y columnas) de la matriz. Obtener el elemento que está en la fila 2 y columna 1 usando corchetes: m[fila,columna]. Obtener la primera fila completa dejando en blanco la columna: m[fila,].\n1.11 ¿Qué sucede con m si corremos en la consola la operación dim(m) <- c(1, 6)?\n1.12 Construir una matriz de 2 columnas que en cada columna tenga los vectores x e y de abajo usando la función cbind() y otro que haga lo mismo pero con 2 filas usando la función rbind():\n\nx <- c(\"fruta\", \"asado\", \"bebida\")\ny <- c(\"si\", \"no\", \"si\")"
  },
  {
    "objectID": "TPs/TP1.html#funciones",
    "href": "TPs/TP1.html#funciones",
    "title": "Trabajo Práctico 1",
    "section": "2. Funciones",
    "text": "2. Funciones\nLas funciones son scripts de R “enlatados” que hacen una operación con un input (un número o una variable, por ejemplo) y devuelven un output. Los inputs van entre paréntedis y separados por una coma, si hay más de uno. Muchas funciones están disponibles en R-base cuando abrimos una sesión de R, class(), length() o c() que usamos en los ejercicios anteriores. El objetivo de estos ejercicios es familiarizarse con varias funciones básicas de R.\n2.1. Ejecutar estas operaciones en la consola para entender qué hacen las funciones sqrt(), round(), args(), ceiling() y floor():\n\nsqrt(81)\nround(3.14159, digits = 3)\nround(3.14159)\nround(digits = 2, 3.14159)\nargs(sample)\n?ceiling y ?floor\n\n2.2 Explorar las funciones max(), min(), mean() y sort() aplicadas al vector alturas_cm del ejercicio 1.6. ¿Qué hace cada una?\n2.3 Usar las funciones which.min() y which.max() con el mismo vector de alturas. Interpretar qué hace cada una.\n2.4. Completar los blancos con distintos números para entender qué hacen las funciones seq() y rep(). Si hay dudas, ?rep y ?seq en la consola.\n\nseq(from = ___, to = ___, lenght.out = ___)\nrep(x = ___, times = ___)\n\n2.5 Reproducir estos usos de la función sample() en la consola e interpretar qué hace esta función.\n\nsample(x = c(\"frambuesa\", \"frutilla\"), size = 7, replace = TRUE )\nsample(x = c(0,1), size = 7, replace = TRUE )\ninventar otros 2 usos de la función sample().\n\n2.6 ¿Por qué da error esta operación?\n\nsample(x = c(-1,1), size = 3)\n\n2.7 Usar la función sum() para sumar los números del 1 al 100 inclusive.\n2.8 R está pensado para analizar datos, entonces tiene formas particulares de tratar datos faltantes. Explorar en la consola el output de estas líneas de código. ¿Qué significa na.rm = TRUE?\n\nn <- c(2, 4, 4, NA, 6)\nmean(n)\nmax(n)\nmean(n, na.rm = TRUE)\nmax(n, na.rm = TRUE)\n\n2.9 A partir de este vector de pesos en Kg de distintas personas:\n\npeso_kg <- c(63, 69, 60, 65, NA, 68, 61, 70, 61, 59, 64, 69, 63, 63, NA, 72, 65, 64, 70, 63, 65)\n\n\nConstruir otro vector que descarte los NA.\nUsar la función mean() para calcular el peso promedio.\nEscribir una línea código que calcule cuántas personas pesan más que 65 kg.\nEscribir una línea de código que calcule cuántas personas pesan 63 kg.\n\n2.10 Usar la función sample() para simular el resultado de tirar un dado.\n2.11 Simular el resultado de tirar 120 veces un dado y contar cuántas veces salió cada resultado. ¿Qué resultado esperás obtener? ¿Coincide el resultado con lo que esperabas? No hay una única forma de resolverlo. Ayuda: sum(___ == x) o averigue cómo se usa la función table().\n2.12 Usar la función sample() para simular el resultado de tirar una moneda cargada, cuya probabilidad de salir cara es 0.7. Ayuda: ver cómo el argumento prob en ?sample."
  },
  {
    "objectID": "TPs/TP1.html#scripts",
    "href": "TPs/TP1.html#scripts",
    "title": "Trabajo Práctico 1",
    "section": "3. Scripts",
    "text": "3. Scripts\nTrabajar en la consola no siempre es lo más conveniente. Lo ideal es escribir en el editor de RStudio un archivo .R (o bien un archivo RMarkdown como veremos más adelante).\n3.1 Crear un script de R que haga la siguientes tres operaciones y guardarlo en un archivo llamado TP1-01.R. Correrlo línea por línea.\n\nx1 <- 2  # defino la variable x1\nx2 <- 3  # defino la variable x2\ny <- x1 + 2*x2\ny\n\n3.2 Crear un script que contenga la resolución completa del ejercicio 2.9. Incluir el enunciado y comentarios en el código. Guardarlo en un archivo “.R”."
  },
  {
    "objectID": "TPs/TP1.html#data-frames",
    "href": "TPs/TP1.html#data-frames",
    "title": "Trabajo Práctico 1",
    "section": "4. Data frames",
    "text": "4. Data frames\nUn data frame es una representación de los datos en formato de tabla en la que cada columna son vectores del mismo tamaño. Como cada columna es un vector, cada columna puede contener datos de un único tipo (ejemplo: numeric, character, factor, logic, etc). Se pueden pensar como variables. Por ejemplo:\nd <-  data.frame(x = 1:5, y = letters[1:5], z = c(T,T,F,T,F))\n4.1. ¿Cuál es la clase del objeto d? ¿Cuál es la clase de cada uno de los vectores columna?\n4.2. Extraer el vector columna y usando $. Comparar con usar d[,2].\n4.3. Cargar el paquete de R gapminder usando library(gapminder). Si da error es posible que no esté instalado. En tal caso ejecutan install.packages(\"gapminder\") en la consola y luego si library(gapminder).\n4.4. ¿Qué variables tiene el dataset gapminder y de qué clase son? Ayuda: usar la función head(gapminder) y/o str(gapminder). Este dataset tiene formato tibble que a los efectos prácticos en este punto es exactamente igual que un data frame.\n4.5. ¿De cuántos países hay datos? Ayuda: averiguar qué hace la función unique().\n4.6 Explorar el tamaño del dataset gapminder usando las funciones dim(), nrow() y ncol().\n4.7 ¿Cuáles son las variables? Usar la función names().\n4.8 Extraer la información de Argentina, Uruguay y Chile y guardarla en un nuevo data frame gm.sur. ¿Cuántas filas tiene? ¿Cuál es el primero y el último año para el cuál existen datos de Argentina en gapminder?\n4.9 ¿Qué resulta de hacer gm.sur[,\"pop\"]? ¿Qué resulta de hacer gm.sur[,-(1:3)]? Explorar el contenido de este data frame en el visor de RStudio haciendo View(gm.sur)\n4.10 Las variables de clase “factor” (factores, o fct) son una clase especial que tiene R para trabajar con variables categóricas. Una vez que se crean, los factores sólo pueden contener un conjunto pre-definido de valores que se conocen como los niveles del factor. ¿Qué variables del dataset de gapminder son factores?\n4.11 Redefinir niveles. Supongamos que queremos cambiar la denominación del continente de Argentina a “América” (sin la s final). Prueben lo siguiente. ¿Qué pasó? ¿Por qué no funciona?\n\nclass(gm.sur$continent)\ngm.sur$continent <- \"America\"\nclass(gm.sur$continent)\n\nAhora prueben esto. ¿Entienden por qué funciona?\n\nlevels(gm.sur$continent) <- c(\"Africa\", \"America\", \"Asia\", \"Europe\", \"Oceania\")\nclass(gm.sur$continent)\nhead(gm.sur)\n\n4.12. Vamos a usar mucho “factores” a lo largo del curso, pero para que se den una idea, por ejemplo, los factores son muy útiles para codificar variables categóricas en gráficos. Vamos a ver esto bastante a lo largo de las clases, pero para que vean una aplicación simple, corran estas líneas usando el paquete (que vamos a ver en las próximas clases) ggplot2.\n\nlibrary(ggplot2)\n\nggplot(data = gm.sur, \n       mapping = aes(x = year, y = pop, col = country)) +\n  geom_point(size = 3) +\n  theme_classic()\n\nAhora corran lo siguiente. ¿En qué difiere del anterior? ¿Pueden intuir por qué tenemos ese resultado?\n\nggplot(data = gm.sur, \n       mapping = aes(x = year, y = pop, size = country)) +\n  geom_point() +\n  theme_classic()\n\n¿Y si reemplazan size por shape dentro de aes(...)?\n4.13. Cambien más cosas del código anterior y prueben el resultado. De hecho, cambiar cosas y ver qué pasa es una gran forma de aprender."
  },
  {
    "objectID": "guias.html",
    "href": "guias.html",
    "title": "Guías",
    "section": "",
    "text": "Guía 1\nGuía 2\nGuía 3\nGuía 4\nGuía 5\nGuía 6\nTP-1"
  },
  {
    "objectID": "guias/guia1.html",
    "href": "guias/guia1.html",
    "title": "Guía 1",
    "section": "",
    "text": "El objetivo de estos ejercicios es reconocer, crear y hacer operaciones simples con los 5 tipos de objetos básicos de R:\n\ncharacter\nnumeric (números reales)\ninteger\ncomplex\nlogical (True/False)\n\nTambién familiarizarse con la consola de R, con matrices y con operaciones lógicas.\n1.1 Realizar las siguientes operaciones básicas en la consola\n\n2+2\na <- 2\nb <- 5\na**3\n16 %% 5 (probar con otros números para entender qué significa)\n2*a**2+0.5*b+(a+b)/2\nasignar el resultado anterior a la variable c\nimprimir el contenido de c en la consola (corriendo c o print(c)). ¿Ven un [1] delante del valor de c? Esto indica que es un vector.\n\n1.2 Interpretar las siguientes operaciones lógicas y predecir el resultado antes de probar en la consola.\n\na <- TRUE\nb <- FALSE\na == b\na || b\na == !b\n\n1.3. Antes de probar en la consola, piense que van a dar estas operaciones:\n\na <- 3\nb <- 4\na > b\na <= b\na != b\nx <- 2\n(x > a) && (10*x>b) || !(b/a>x)\n\n1.4 Los vectores en R se crean con la función c(). Por ejemplo c(2,-1) es un vector de clase numeric que tiene dos elementos, el 2 y el -1. Se puede comprobar usando la función class() así: class(c(2,-1)). Crear 5 vectores de 2 componentes de las siguiente clases básicas: character, numeric, integer, complex y logical (True/False).\n1.5. ¿Qué sucede cuando se realizan las siguientes operaciones que mezclan variables de distinta clase? ¿Por qué les parece que pasa? (usar class() para investigar el tipo de dato de los objetos)\n\nnum_char <- c(1, 2, 3, \"a\")\nnum_logical <- c(1, 2, 3, TRUE)\nchar_logical <- c(\"a\", \"b\", \"c\", TRUE)\ntramposo <- c(1, 2, 3, \"4\")\n\n1.6. Realizar las siguientes operaciones en la consola, ver el output de cada operación y escribir una frase explicando qué hace cada una.\n\nalturas_cm <- c(180, 178, 154, 202)\nfrutas <- c(\"banana\", \"pera\", \"durazno\")\nlength(alturas_cm)\nlength(frutas)\nfrutas <- c(frutas, \"uva\")\nfrutas <- c(\"naranja\", frutas)\nbajitos <- (alturas_cm < 165)\nclass(bajitos)\n1:10\n21:30\n\n1.7. Explorar estas distintas formas de extraer información del vector c(\"banana\", \"pera\", \"durazno\", \"anana\"). Primero crear el vector en la consola y asignarlo al vector frutas. Luego correr cada caso en la consola y explicar en pocas palabras qué es lo que sucede.\n\nfrutas[2]\nfrutas[c(1,4)]\nfrutas[c(1,4,1,1,2)]\nfrutas %in% c(\"ciruela\", \"frutilla\", \"pera\", \"mandarina\")\nfrutas[ frutas %in% c(\"ciruela\", \"frutilla\", \"pera\", \"mandarina\") ]\n\n1.8. ¿Por qué da error la línea 4 de esta secuencia?\n\ndatos <- c(\"banana\", 2, \"pera\", 5, \"durazno\", 0)\ndatos[2] \ndatos[4]\ndatos[2] + datos[4]\n\n1.9. Explorar distintas formas de extraer información del vector alturas_cm definido en el ejercicio 1.6. Escribir una frase explicando qué hace cada una. ¿Por qué la última retorna numeric(0)?\n\nalturas_cm[c(TRUE, FALSE, TRUE, TRUE)]\nalturas_cm[alturas_cm >= 180]\nalturas_cm[alturas_cm >= 180 & alturas_cm < 200]\nalturas_cm[alturas_cm >= 160 & alturas_cm == 195]\n\n1.10. Las matrices en R son vectores con estructura en 2D. Por ejemplo, se pueden crear de esta forma\n\nm <- matrix(1:6, nrow = 2, ncol = 3)\n\nUsar dim(m) para averiguar el atributo “dimesión” (número de filas y columnas) de la matriz. Obtener el elemento que está en la fila 2 y columna 1 usando corchetes: m[fila,columna]. Obtener la primera fila completa dejando en blanco la columna: m[fila,].\n1.11 ¿Qué sucede con m si corremos en la consola la operación dim(m) <- c(1, 6)?\n1.12 Construir una matriz de 2 columnas que en cada columna tenga los vectores x e y de abajo usando la función cbind() y otro que haga lo mismo pero con 2 filas usando la función rbind():\n\nx <- c(\"fruta\", \"asado\", \"bebida\")\ny <- c(\"si\", \"no\", \"si\")"
  },
  {
    "objectID": "guias/guia1.html#funciones",
    "href": "guias/guia1.html#funciones",
    "title": "Guía 1",
    "section": "2. Funciones",
    "text": "2. Funciones\nLas funciones son scripts de R “enlatados” que hacen una operación con un input (un número o una variable, por ejemplo) y devuelven un output. Los inputs van entre paréntedis y separados por una coma, si hay más de uno. Muchas funciones están disponibles en R-base cuando abrimos una sesión de R, class(), length() o c() que usamos en los ejercicios anteriores. El objetivo de estos ejercicios es familiarizarse con varias funciones básicas de R.\n2.1. Ejecutar estas operaciones en la consola para entender qué hacen las funciones sqrt(), round(), args(), ceiling() y floor():\n\nsqrt(81)\nround(3.14159, digits = 3)\nround(3.14159)\nround(digits = 2, 3.14159)\nargs(sample)\n?ceiling y ?floor\n\n2.2 Explorar las funciones max(), min(), mean() y sort() aplicadas al vector alturas_cm del ejercicio 1.6. ¿Qué hace cada una?\n2.3 Usar las funciones which.min() y which.max() con el mismo vector de alturas. Interpretar qué hace cada una.\n2.4. Completar los blancos con distintos números para entender qué hacen las funciones seq() y rep(). Si hay dudas, ?rep y ?seq en la consola.\n\nseq(from = ___, to = ___, lenght.out = ___)\nrep(x = ___, times = ___)\n\n2.5 Reproducir estos usos de la función sample() en la consola e interpretar qué hace esta función.\n\nsample(x = c(\"frambuesa\", \"frutilla\"), size = 7, replace = TRUE )\nsample(x = c(0,1), size = 7, replace = TRUE )\ninventar otros 2 usos de la función sample().\n\n2.6 ¿Por qué da error esta operación?\n\nsample(x = c(-1,1), size = 3)\n\n2.7 Usar la función sum() para sumar los números del 1 al 100 inclusive.\n2.8 R está pensado para analizar datos, entonces tiene formas particulares de tratar datos faltantes. Explorar en la consola el output de estas líneas de código. ¿Qué significa na.rm = TRUE?\n\nn <- c(2, 4, 4, NA, 6)\nmean(n)\nmax(n)\nmean(n, na.rm = TRUE)\nmax(n, na.rm = TRUE)\n\n2.9 A partir de este vector de pesos en Kg de distintas personas:\n\npeso_kg <- c(63, 69, 60, 65, NA, 68, 61, 70, 61, 59, 64, 69, 63, 63, NA, 72, 65, 64, 70, 63, 65)\n\n\nConstruir otro vector que descarte los NA.\nUsar la función mean() para calcular el peso promedio.\nEscribir una línea código que calcule cuántas personas pesan más que 65 kg.\nEscribir una línea de código que calcule cuántas personas pesan 63 kg.\n\n2.10 Usar la función sample() para simular el resultado de tirar un dado.\n2.11 Simular el resultado de tirar 120 veces un dado y contar cuántas veces salió cada resultado. ¿Qué resultado esperás obtener? ¿Coincide el resultado con lo que esperabas? No hay una única forma de resolverlo. Ayuda: sum(___ == x) o averigue cómo se usa la función table().\n2.12 Usar la función sample() para simular el resultado de tirar una moneda cargada, cuya probabilidad de salir cara es 0.7. Ayuda: ver cómo el argumento prob en ?sample."
  },
  {
    "objectID": "guias/guia1.html#scripts",
    "href": "guias/guia1.html#scripts",
    "title": "Guía 1",
    "section": "3. Scripts",
    "text": "3. Scripts\nTrabajar en la consola no siempre es lo más conveniente. Lo ideal es escribir en el editor de RStudio un archivo .R (o bien un archivo RMarkdown como veremos más adelante).\n3.1 Crear un script de R que haga la siguientes tres operaciones y guardarlo en un archivo llamado TP1-01.R. Correrlo línea por línea.\n\nx1 <- 2  # defino la variable x1\nx2 <- 3  # defino la variable x2\ny <- x1 + 2*x2\ny\n\n3.2 Crear un script que contenga la resolución completa del ejercicio 2.9. Incluir el enunciado y comentarios en el código. Guardarlo en un archivo “.R”."
  },
  {
    "objectID": "guias/guia1.html#data-frames",
    "href": "guias/guia1.html#data-frames",
    "title": "Guía 1",
    "section": "4. Data frames",
    "text": "4. Data frames\nUn data frame es una representación de los datos en formato de tabla en la que cada columna son vectores del mismo tamaño. Como cada columna es un vector, cada columna puede contener datos de un único tipo (ejemplo: numeric, character, factor, logic, etc). Se pueden pensar como variables. Por ejemplo:\nd <-  data.frame(x = 1:5, y = letters[1:5], z = c(T,T,F,T,F))\n4.1. ¿Cuál es la clase del objeto d? ¿Cuál es la clase de cada uno de los vectores columna?\n4.2. Extraer el vector columna y usando $. Comparar con usar d[,2].\n4.3. Cargar el paquete de R gapminder usando library(gapminder). Si da error es posible que no esté instalado. En tal caso ejecutan install.packages(\"gapminder\") en la consola y luego si library(gapminder).\n4.4. ¿Qué variables tiene el dataset gapminder y de qué clase son? Ayuda: usar la función head(gapminder) y/o str(gapminder). Este dataset tiene formato tibble que a los efectos prácticos en este punto es exactamente igual que un data frame.\n4.5. ¿De cuántos países hay datos? Ayuda: averiguar qué hace la función unique().\n4.6 Explorar el tamaño del dataset gapminder usando las funciones dim(), nrow() y ncol().\n4.7 ¿Cuáles son las variables? Usar la función names().\n4.8 Extraer la información de Argentina, Uruguay y Chile y guardarla en un nuevo data frame gm.sur. ¿Cuántas filas tiene? ¿Cuál es el primero y el último año para el cuál existen datos de Argentina en gapminder?\n4.9 ¿Qué resulta de hacer gm.sur[,\"pop\"]? ¿Qué resulta de hacer gm.sur[,-(1:3)]? Explorar el contenido de este data frame en el visor de RStudio haciendo View(gm.sur)\n4.10 Las variables de clase “factor” (factores, o fct) son una clase especial que tiene R para trabajar con variables categóricas. Una vez que se crean, los factores sólo pueden contener un conjunto pre-definido de valores que se conocen como los niveles del factor. ¿Qué variables del dataset de gapminder son factores?\n4.11 Redefinir niveles. Supongamos que queremos cambiar la denominación del continente de Argentina a “América” (sin la s final). Prueben lo siguiente. ¿Qué pasó? ¿Por qué no funciona?\n\nclass(gm.sur$continent)\ngm.sur$continent <- \"America\"\nclass(gm.sur$continent)\n\nAhora prueben esto. ¿Entienden por qué funciona?\n\nlevels(gm.sur$continent) <- c(\"Africa\", \"America\", \"Asia\", \"Europe\", \"Oceania\")\nclass(gm.sur$continent)\nhead(gm.sur)\n\n4.12. Vamos a usar mucho “factores” a lo largo del curso, pero para que se den una idea, por ejemplo, los factores son muy útiles para codificar variables categóricas en gráficos. Vamos a ver esto bastante a lo largo de las clases, pero para que vean una aplicación simple, corran estas líneas usando el paquete (que vamos a ver en las próximas clases) ggplot2.\n\nlibrary(ggplot2)\n\nggplot(data = gm.sur, \n       mapping = aes(x = year, y = pop, col = country)) +\n  geom_point(size = 3) +\n  theme_classic()\n\nAhora corran lo siguiente. ¿En qué difiere del anterior? ¿Pueden intuir por qué tenemos ese resultado?\n\nggplot(data = gm.sur, \n       mapping = aes(x = year, y = pop, size = country)) +\n  geom_point() +\n  theme_classic()\n\n¿Y si reemplazan size por shape dentro de aes(...)?\n4.13. Cambien más cosas del código anterior y prueben el resultado. De hecho, cambiar cosas y ver qué pasa es una gran forma de aprender."
  },
  {
    "objectID": "slides/clase1.html#vacantes",
    "href": "slides/clase1.html#vacantes",
    "title": "Laboratorio de datos",
    "section": "Vacantes",
    "text": "Vacantes\n\n¿A todos los presentes les llegó un mail confirmando la vacante?\nSi no pueden cursar, avisen a la brevedad porque hay inscriptos en lista de espera."
  },
  {
    "objectID": "slides/clase1.html#estructura-de-la-materia",
    "href": "slides/clase1.html#estructura-de-la-materia",
    "title": "Laboratorio de datos",
    "section": "Estructura de la materia",
    "text": "Estructura de la materia\n\nTeórico-práctica\nLaboratorio 1103!\nR\nPara aprobar la materia es necesario:\n\nAsistir al ~80% de las clases (11 clases).\nTrabajar en clase.\nAprobar 2 TPs grupales (nota mayor o igual a 4).\nAprobar el parcial individual (nota mayor a 6).\n\nNota final = \\(0.6 \\times \\text{nota parcial} + 0.2 \\times \\text{nota TP1} + 0.2 \\times \\text{nota TP2} + x\\)\n\n\\[\nx = \\left\\{\\begin{aligned}\n          1 & \\text{ si el promedio de los TPs es mayor o igual a 8}\\\\\n          0 & \\text{ si el promedio de los TPs es menor a 8}\n        \\end{aligned}\\right.\n\\]"
  },
  {
    "objectID": "slides/clase1.html#docentes",
    "href": "slides/clase1.html#docentes",
    "title": "Laboratorio de datos",
    "section": "Docentes",
    "text": "Docentes\n\nDario Elías (ayudante de primera)\nYamila Alen (ayudante de primera)\nGuillermo Solovey (profesor)"
  },
  {
    "objectID": "slides/clase1.html#comunicación",
    "href": "slides/clase1.html#comunicación",
    "title": "Laboratorio de datos",
    "section": "Comunicación",
    "text": "Comunicación\n\nPágina de la materia: ldd2023.netlify.app\nListas de mail:\n\nldd2023-alu@googlegroups.com: los mails le llegan a TODOS: alumnos y docentes\nldd2023-doc@googlegroups.com: los mails le llegan SÓLO a los docentes (desde hoy a la tarde!)."
  },
  {
    "objectID": "slides/clase1.html#fecha-de-parcial",
    "href": "slides/clase1.html#fecha-de-parcial",
    "title": "Laboratorio de datos",
    "section": "Fecha de parcial",
    "text": "Fecha de parcial\n\nParcial. Viernes 17 de noviembre.\nRecuperatorio. Viernes 1 de diciembre.\nPor inconvenientes con las fechas completar a la brevedad este formulario y vemos de adelantarles la fecha."
  },
  {
    "objectID": "slides/clase1.html#programa-de-la-materia",
    "href": "slides/clase1.html#programa-de-la-materia",
    "title": "Laboratorio de datos",
    "section": "Programa de la materia",
    "text": "Programa de la materia\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfecha\n      tema\n      slides\n      tp\n    \n\n\n18/8\nIntroducción a la materia. Ciencia de datos. Tipos de preguntas. Introducción a R y RStudio | Charla Dátame.\n\n\n\n\n25/8\nEstadística descriptiva. Visualización. Gramática de gráficos.\n\n\n\n\n1/9\nAnálisis exploratorio de datos y comunicación.\n\n\n\n\n8/9\nTransformación de datos: datos ordenados, vectores, data frames. Unión de data frames.\n\n\n\n\n15/9\nProgramación en R: funciones, iteraciones | Charla Dátame.\n\n\n\n\n22/9\nReproducibilidad computacional. Comunicación e informes con RMarkdown/Quarto.\n\nPresentación TP1\n\n\n29/9\nIntroducción al modelado. Modelos supervisados y no supervisados. Regresión vs. clasificación. Trade-off sesgo-varianza. Modelo de regresión lineal simple.\n\nConsultas TP1\n\n\n6/10\nRegresión: regresión lineal múltiple y K-nearest neighbors.\n\nEnvío TP1 (límite: 5 de Oct, 23:59)\n\n\n13/10\nFeriado\n\n\n\n\n20/10\nClasificación: Árboles de decisión y K-nearest neighbors | Charla Dátame.\n\nDevolución TP1\n\n\n27/10\nHerramientas de validación de un\nmodelo. Métodos de resampleo. Muestras de testeo y entrenamiento.Métricas\n\nPresentación TP2\n\n\n3/11\nAprendizaje no supervisado. Métodos de clustering: K-means y clustering jerárquico.\n\nConsultas TP2\n\n\n10/11\nConsultas.\n\nEnvío TP2 (límite: 9 de Nov, 23:59)\n\n\n17/11\nParcial de 10 a 13hs en aula a confirmar | Charla Dátame.\n\n\n\n\n24/11\nEntrega de notas del parcial y TP2. Cierre\n\n\n\n\n1/12\nRecuperatorio del parcial, de 10 a 13hs en aula a confirmar.\n\nRe-entrega de TPs.\n\n\n8/12\nEntrega de notas del recuperatorio y de los TPs. Cierre."
  },
  {
    "objectID": "slides/clase1.html#material-de-estudio",
    "href": "slides/clase1.html#material-de-estudio",
    "title": "Laboratorio de datos",
    "section": "Material de estudio",
    "text": "Material de estudio\n\nlos slides de las clases son material didáctico.\nla bibliografía de referencia va a estar en las slides de cada clase.\ntraer cuaderno (no cuenten sólo con la computadora).\nno se queden únicamente con lo que hacen en clase. se requiere mucha práctica."
  },
  {
    "objectID": "slides/clase1.html#r-rstudio",
    "href": "slides/clase1.html#r-rstudio",
    "title": "Laboratorio de datos",
    "section": "R / RStudio",
    "text": "R / RStudio\n\nvamos a usar mucho R.\nla clase de hoy es una introducción para que se familiaricen."
  },
  {
    "objectID": "slides/clase1.html#rstudio",
    "href": "slides/clase1.html#rstudio",
    "title": "Laboratorio de datos",
    "section": "RStudio",
    "text": "RStudio"
  },
  {
    "objectID": "slides/clase1.html#rstudio-1",
    "href": "slides/clase1.html#rstudio-1",
    "title": "Laboratorio de datos",
    "section": "RStudio",
    "text": "RStudio"
  },
  {
    "objectID": "slides/clase1.html#rstudio-2",
    "href": "slides/clase1.html#rstudio-2",
    "title": "Laboratorio de datos",
    "section": "RStudio",
    "text": "RStudio"
  },
  {
    "objectID": "slides/clase1.html#rstudio-3",
    "href": "slides/clase1.html#rstudio-3",
    "title": "Laboratorio de datos",
    "section": "RStudio",
    "text": "RStudio"
  },
  {
    "objectID": "slides/clase1.html#rstudio-4",
    "href": "slides/clase1.html#rstudio-4",
    "title": "Laboratorio de datos",
    "section": "RStudio",
    "text": "RStudio"
  },
  {
    "objectID": "slides/clase1.html#programa",
    "href": "slides/clase1.html#programa",
    "title": "Laboratorio de datos",
    "section": "Programa",
    "text": "Programa\nEn líneas generales:\n\nOrganización de datos.\nVisualización, descripción y análisis exploratorio de datos.\nModelado de datos (modelos explicativos y predictivos).\n Cronograma"
  },
  {
    "objectID": "slides/clase1.html#ciencia-de-datos",
    "href": "slides/clase1.html#ciencia-de-datos",
    "title": "Laboratorio de datos",
    "section": "Ciencia de datos",
    "text": "Ciencia de datos\n\n“…allows you to turn raw data into understanding, insight, and knowledge” (Wickham, Çetinkaya-Rundel, and Grolemund). https://r4ds.hadley.nz/\n“…the process of formulating a quantitative question that can be answered with data, collecting and cleaning the data, analyzing the data, and communicating the answer to the question to a relevant audience” (Leek and Peng). http://jtleek.com/ads2020/\n“…the process of generating insight from data through reproducible and auditable processes” (Timbers, Campbell, and Lee). https://datasciencebook.ca/"
  },
  {
    "objectID": "slides/clase1.html#tipo-de-preguntas",
    "href": "slides/clase1.html#tipo-de-preguntas",
    "title": "Laboratorio de datos",
    "section": "Tipo de preguntas",
    "text": "Tipo de preguntas\n\nSe define por las preguntas que se hace: es la ciencia que usa datos para describir, explicar y predecir.\nNo se define por las técnicas: no es la ciencia que usa deep learning.\n\n\n\ndescriptiva: resumir caracteristicas de un data set. sin interpretación, como atributos de los datos (LdD + IECS).\nexploratorias: buscar patrones, tendencias, relaciones entre variables. sirve para generar hipótesis (LdD)\ninferenciales: evaluar hipotesis, respecto a un patron encontrado en un análisis exploratorio (lo van a ver en IECS).\npredictivas: adivinar qué va a suceder, sin importar la causa (LdD,…).\ncausales: ¿cambiar una variable, cambia el valor de otra variable? ej.: test A/B\nmecanisticas: ¿cómo ocurre?\n\n\n\nThe art of data science"
  },
  {
    "objectID": "slides/clase1.html#referencias",
    "href": "slides/clase1.html#referencias",
    "title": "Laboratorio de datos",
    "section": "Referencias",
    "text": "Referencias\n\nThe art of data science"
  },
  {
    "objectID": "guias/guia1.html#referencias",
    "href": "guias/guia1.html#referencias",
    "title": "Guía 1",
    "section": "Referencias",
    "text": "Referencias\n\nR Programming for Data Science. Roger D. Peng.\nR for Data Science (2e). Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund.\nR para Ciencia de Datos. Hadley Wickham y Garrett Grolemund.\nLearning statistics with R. Danielle Navarro.\nR para profesionales de los datos: una introducción. Carlos J. Gil Bellosta.\nData Science. A First Introduction. Tiffany Timbers, Trevor Campbell, and Melissa Lee."
  },
  {
    "objectID": "slides/clase1.html#qué-es-la-ciencia-de-datos",
    "href": "slides/clase1.html#qué-es-la-ciencia-de-datos",
    "title": "Laboratorio de datos",
    "section": "¿Qué es la ciencia de datos?",
    "text": "¿Qué es la ciencia de datos?\n\n“…allows you to turn raw data into understanding, insight, and knowledge” (Wickham, Çetinkaya-Rundel, and Grolemund). https://r4ds.hadley.nz/\n“…the process of formulating a quantitative question that can be answered with data, collecting and cleaning the data, analyzing the data, and communicating the answer to the question to a relevant audience” (Leek and Peng). http://jtleek.com/ads2020/\n“…the process of generating insight from data through reproducible and auditable processes” (Timbers, Campbell, and Lee). https://datasciencebook.ca/\n\nTarea para el 25/8: leer el capítulo 1 de Telling Stories with data"
  },
  {
    "objectID": "slides/clase1.html#preguntas-para-pensar-en-grupos",
    "href": "slides/clase1.html#preguntas-para-pensar-en-grupos",
    "title": "Laboratorio de datos",
    "section": "Preguntas… (para pensar en grupos)",
    "text": "Preguntas… (para pensar en grupos)\n\nEJEMPLO"
  },
  {
    "objectID": "slides/clase1.html#qué-es-la-ciencia-de-datos-1",
    "href": "slides/clase1.html#qué-es-la-ciencia-de-datos-1",
    "title": "Laboratorio de datos",
    "section": "¿Qué es la ciencia de datos?",
    "text": "¿Qué es la ciencia de datos?\n\nSe define por las preguntas que se hace: es la ciencia que usa datos para describir, explicar y predecir.\nNo se define por las técnicas: no es la ciencia que usa deep learning."
  },
  {
    "objectID": "slides/clase1.html#qué-es-la-ciencia-de-datos-2",
    "href": "slides/clase1.html#qué-es-la-ciencia-de-datos-2",
    "title": "Laboratorio de datos",
    "section": "¿Qué es la ciencia de datos?",
    "text": "¿Qué es la ciencia de datos?\nTaxonomía de preguntas:\n\n\ndescriptiva: resumir caracteristicas de un data set. sin interpretación, como atributos de los datos (LdD + IECS).\nexploratorias: buscar patrones, tendencias, relaciones entre variables. sirve para generar hipótesis (LdD)\ninferenciales: evaluar hipotesis, respecto a un patron encontrado en un análisis exploratorio (lo van a ver en IECS).\npredictivas: adivinar qué va a suceder, sin importar la causa (LdD,…).\ncausales: ¿cambiar una variable, cambia el valor de otra variable? ej.: test A/B\nmecanisticas: ¿cómo ocurre?\nTarea para el 25/8: leer el capítulo 1-3 de The art of data science"
  },
  {
    "objectID": "slides/clase2.html#docentes",
    "href": "slides/clase2.html#docentes",
    "title": "Laboratorio de datos",
    "section": "Docentes",
    "text": "Docentes\n\n\n\n\n\n\nPay Attention\n\n\nUsing callouts is an effective way to highlight content that your reader give special consideration or attention."
  },
  {
    "objectID": "slides/clase2.html#estadística-descriptiva",
    "href": "slides/clase2.html#estadística-descriptiva",
    "title": "Laboratorio de datos",
    "section": "Estadística descriptiva",
    "text": "Estadística descriptiva\n\n\n\n\n\n\nResumir"
  },
  {
    "objectID": "slides/clase2.html#datos",
    "href": "slides/clase2.html#datos",
    "title": "Laboratorio de datos",
    "section": "Datos:",
    "text": "Datos:"
  },
  {
    "objectID": "slides/clase2.html#tres-ideas",
    "href": "slides/clase2.html#tres-ideas",
    "title": "Laboratorio de datos",
    "section": "Tres ideas",
    "text": "Tres ideas\n\ndistribución\nmedidas de centralidad\nmedidas de variabilidad"
  },
  {
    "objectID": "slides/clase2.html#medidas-de-centralidad",
    "href": "slides/clase2.html#medidas-de-centralidad",
    "title": "Laboratorio de datos",
    "section": "Medidas de centralidad",
    "text": "Medidas de centralidad\n\nresumir en un único número!\nModa\n\n1 1 1 2 3 4 5 6\n1 1 1 2 2 2 5 6\n¿es buena la moda? 1 1 2 3 4 6 7 9\n\n\n\nMediana\n\n1 3 4 5 6 7 9\n1 5 4 3 6 7 9\n1 2 3 4 5 6\n¿es buena la mediana? 1 2 3 4 4 4 5 6 6 6 7 7 1000\n\n\n\nMedia (promedio)\n\n\\(\\frac{1}{n}\\sum_i^n x_i\\)\n3 7 9 2 6"
  },
  {
    "objectID": "slides/clase2.html#medidas-de-centralidad-1",
    "href": "slides/clase2.html#medidas-de-centralidad-1",
    "title": "Laboratorio de datos",
    "section": "Medidas de centralidad",
    "text": "Medidas de centralidad\n\nejemplo de histograma con media, mediana y moda.\nla mediana y la moda son insensibles a valores atípicos (por ejemplo valores extremos que son poco frecuentes0)."
  },
  {
    "objectID": "slides/clase2.html#medidas-de-variabilidad",
    "href": "slides/clase2.html#medidas-de-variabilidad",
    "title": "Laboratorio de datos",
    "section": "Medidas de variabilidad",
    "text": "Medidas de variabilidad\n\nmostrar que el promedio de distancias abs no sirve\nvarianza: sum de sq diff / n\nThe mean is the balancing point in the data\nsd = sqrt(varianza)"
  },
  {
    "objectID": "slides/clase2.html#anscombe",
    "href": "slides/clase2.html#anscombe",
    "title": "Laboratorio de datos",
    "section": "Anscombe",
    "text": "Anscombe"
  },
  {
    "objectID": "slides/clase2.html#cuarteto-de-anscombe",
    "href": "slides/clase2.html#cuarteto-de-anscombe",
    "title": "Laboratorio de datos",
    "section": "Cuarteto de Anscombe",
    "text": "Cuarteto de Anscombe\n\n\nPlot\nResumen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n quartet \n    mean_x \n    var_x \n    mean_y \n    var_y \n  \n\n\n 1 \n    9 \n    11 \n    7.5 \n    4.13 \n  \n\n 2 \n    9 \n    11 \n    7.5 \n    4.13 \n  \n\n 3 \n    9 \n    11 \n    7.5 \n    4.12 \n  \n\n 4 \n    9 \n    11 \n    7.5 \n    4.12"
  },
  {
    "objectID": "slides/clase2.html#cuarteto-de-anscombe-1",
    "href": "slides/clase2.html#cuarteto-de-anscombe-1",
    "title": "Laboratorio de datos",
    "section": "Cuarteto de Anscombe",
    "text": "Cuarteto de Anscombe\n\n\n\n\n\n\nImportant\n\n\nThis is an example of a ‘folded’ caution callout that can be expanded by the user. You can use collapse=\"true\" to collapse it by default or collapse=\"false\" to make a collapsible callout that is expanded by default."
  },
  {
    "objectID": "guias/guia2.html#medidas-de-centralidad-y-variabilidad",
    "href": "guias/guia2.html#medidas-de-centralidad-y-variabilidad",
    "title": "Guía 2",
    "section": "1. Medidas de centralidad y variabilidad",
    "text": "1. Medidas de centralidad y variabilidad\n1.0 Definir media, mediana y moda. ¿Qué tiene que pasar para que un conjunto de números tenga dos modas?\n1.1 Definir desvío estándar. ¿Por qué es una medida de variabilidad y por qué la diferencia en el numerador está elevada al cuadraro?\n1.1 Cargar, como en la guía 1, el dataset gapminder del paquete homónimo y calcular la media y mediana de la expectativa de vida en 1952 (lifeExp).\n1.2 Paréntesis: R no tiene una función para calcular la moda. En este ejercicio vamos a crear esa función (de paso aprenden cómo crear funciones en R). - Escriban la definición de la moda. - Si yo les paso un vector, qué pasos necesitaría hacer para calcular la moda. -\n1.3. Generar datos con rnorm(100), guardarlos en un vector y calular la media, mediana y moda\n1.4 Calcular el rango, varianza y el desvío estandar de la expectativa de vida (lifeExp) tomando el dataset gapminder para el año 1952.\n1.5 Calcular la media, varianza y desvío estándar de la expectativa de vida para cada uno de los años reportados en el dataset. Para esto se puede hacer una función. Dar un ejemplo para completar.\n1.6 Calcular la media, la mínima, la máxima y el desvío estándar de la expectativa de vida en cada continente en 1952 y en 2007.\n1.7 Crear un Rmd"
  },
  {
    "objectID": "guias/guia2.html#correlaciones",
    "href": "guias/guia2.html#correlaciones",
    "title": "Guía 2",
    "section": "3. Correlaciones",
    "text": "3. Correlaciones\n3.1 Ejercicios básicos de correlación.\n3.2 Para qué sirve? Dar datos y descripciones posibles para elegir.\n3.3 Jugar a guess the correlation.\n3.4 Generar los datos de McElreath y estimar."
  },
  {
    "objectID": "guias/guia2.html#tipos-de-gráficos",
    "href": "guias/guia2.html#tipos-de-gráficos",
    "title": "Guía 2",
    "section": "1. Tipos de gráficos",
    "text": "1. Tipos de gráficos\npara que sirve cada uno\nTengo datos de una encuesta realizada en distintas provincias de Argentina y quiero saber cuántas personas respondieron a la encuesta en cada provincia. ¿Hago un gráfico de líneas, de dispersión (scatter), histograma o un gráfico de barras (bar plot)? Realizar a mano en tu cuaderno cómo esperás que se vea el gráfico.\nEstás estudiando la relación entre altura y peso de las personas. Tenés un data-set que tiene como variables la edad, sexo y peso de cada persona. Si querés describir estas variables por separado, ¿qué gráfico harías para cada una? ¿y si querés visualizar la relación entre peso y altura? Realizar a mano en tu cuaderno cómo esperás que se vea el gráfico.\nRealizar un gráfico de barras que muestre la cantidad de países hay en cada continente según los datos de gapminder."
  },
  {
    "objectID": "guias/guia2.html#corregir-un-grafico-ya-hecho",
    "href": "guias/guia2.html#corregir-un-grafico-ya-hecho",
    "title": "Guía 2",
    "section": "2. Corregir un grafico ya hecho",
    "text": "2. Corregir un grafico ya hecho\nDar un ggplot y la tarea es imitarlo\nQueremos investigar cómo varía la expectativa de vida entre los continentes. Para eso queremos un gráfico como el siguiente\n\n#! echo: true\nplot_q2 <- ggplot(<arguments>) +\n  geom_<type>(<arguments>) +\n  ...\n\nplot_q2\n\nLooking at the previous plot, which continent has the highest median life expectancy? Which part of the boxplot can we determine this from?\n\n#! echo: false\nggplot(data = gapminder, aes(x = year, y = lifeExp)) +\n         geom_line(aes(group = country), color = \"gray70\") +\n  geom_smooth(aes(group = continent), method = \"lm\") +\n  facet_wrap(~ continent)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "guias/guia2.html#anscombe",
    "href": "guias/guia2.html#anscombe",
    "title": "Guía 2",
    "section": "3. Anscombe",
    "text": "3. Anscombe"
  },
  {
    "objectID": "guias/guia2-template.html",
    "href": "guias/guia2-template.html",
    "title": "Guía 2 - Template para estadística descriptiva",
    "section": "",
    "text": "media: esta es mi definición de media con palabras. también lo puedo escribir en Latex:\n\n\\[ \\text{media}(x) = \\frac{1}{N} \\sum_{i=1}^N  x_i\\]\n\n# así es como lo puedo calcular en R\nx <- c(3,4,2,5,6)\nm1 <- mean(x)\n# lo calculo de otra forma para comprobar\nm2 <- sum(x)/length(x)\nprint(c(m1, m2))\n\n[1] 4 4\n\n\n\nmediana: mi definición de mediana\n\nEn R:\n\n# así es como lo puedo calcular en R\nx <- c(3,4,2,5,6)\nprint(median(x))\n\n[1] 4\n\n\n\nmoda: mi definición de moda\n\n\nx <- c(\"mandarina\", \"mandarina\", \"pera\", \"pera\", \"pera\", \"tomate\")\nt <- table(x)\nnames(___)"
  },
  {
    "objectID": "guias/guia2.html#variables-categóricas-y-numérica",
    "href": "guias/guia2.html#variables-categóricas-y-numérica",
    "title": "Guía 2",
    "section": "1. Variables categóricas y numérica",
    "text": "1. Variables categóricas y numérica\n1.1 Dar tres ejemplos de variables categóricas y numéricas.\n1.2 En el dataset gapminder del paquete homónimo (que ya trabajaron en la guía 1), una de las variables es el producto bruto per capita (gdpPercap). ¿Es una variable categórica (nominal u ordinal) o numérica (discreta o contínua)?\n1.3 Supongamos que definimos una nueva variable que puede tomar los siguientes tres valores:\n\\[\n\\begin{equation}\n  f(x)=\\begin{cases}\n    1, & \\text{if $x<0$}.\\\\\n    0, & \\text{otherwise}.\n  \\end{cases}\n\\end{equation}\n\\]"
  },
  {
    "objectID": "guias/guia2.html#medidas-de-posición-y-dispersión",
    "href": "guias/guia2.html#medidas-de-posición-y-dispersión",
    "title": "Guía 2",
    "section": "2. Medidas de posición y dispersión",
    "text": "2. Medidas de posición y dispersión\n2.1 Definir media, mediana y moda. ¿Qué tiene que pasar para que existan dos modas?\n2.2 R no tiene una función para calcular la moda. Escribir una función de R que calcule la moda de una muestra de datos de variable categórica y probarla con el vector colores y con el variable continent del dataset gapminder. Ayuda: Usar las funciones table y which.max().\n\nmi.moda <- function(x){\n  __ COMPLETAR ACÁ __\n  return(output)\n}\n\n# verifico que funciona\ncolores <- c('blue', 'red', 'green', 'red', 'black', 'yellow','blue','blue')\nmi.moda(colores)\n\n2.3 Calcular la media y mediana de la expectativa de vida entre países en 1952 usando los datos de gapminder (variable: lifeExp).\n2.4 Definir desvío estándar. ¿Por qué la diferencia en el numerador está elevada al cuadrado? Escribir una función de R que calcule el desvío estándar.\n2.5 Calcular el rango, varianza y el desvío estandar de la expectativa de vida (lifeExp) entre países tomando sólo el dataset gapminder para el año 1952. Comparar el resultado de usar la función creada en 2.4 con sd()de R-base.\n2.6 Extra: Guardar este archivo Quarto (.qmd) y abrirlo en RStudio. Completar lo que falta. AGREGAR LINK A GITHUB"
  },
  {
    "objectID": "guias/guia2.html#variables-categóricas-y-numéricas",
    "href": "guias/guia2.html#variables-categóricas-y-numéricas",
    "title": "Guía 2",
    "section": "1. Variables categóricas y numéricas",
    "text": "1. Variables categóricas y numéricas\n1.1 Dar tres ejemplos de variables categóricas y numéricas.\n1.2 En el dataset gapminder del paquete homónimo (que ya trabajaron en la guía 1), una de las variables es el producto bruto per capita de los países (gdpPercap). ¿Es una variable categórica (nominal u ordinal) o numérica (discreta o contínua)?\n1.3 Supongamos que definimos una nueva variable que puede tomar los siguientes valores:\n\\[\n\\begin{equation}\n  I.gdp = \\begin{cases}\n    0, & \\text{si gdpPercap $< 1600$}.\\\\\n    1, & \\text{si $1600 \\le $ gdpPercap $ < 6600$}.\\\\\n    2, & \\text{en otro caso}.\n  \\end{cases}\n\\end{equation}\n\\]\n¿La nueva variable \\(I.gdp\\) es categórica (nominal u ordinal) o numérica (discreta o contínua)? ¿Cambia la respuesta si la variable \\(I.gdp\\) toma valores “bajo”, “medio” y “alto” en lugar de 0, 1, 2?\n1.4 Calcular la proporción de países en cada continente usando la función prop.table() y la función table(). Buscar en la ayuda de RStudio cuál es el argumento de la función prop.table().\n1.5 Crear una variable \\(I\\) que valga 1 si gdpPercap es mayor que 2000 dólares y 0 si no lo es. Luego crear una tabla de 2 filas y 5 columnas que calcule la cantidad de países donde \\(I=\\{0,1\\}\\) en cada continente. Usar la función table() apropiadamente.\n1.6 Convertir el vector colores a factor y comprobar que funcionó usando la función class(). Verificar las categorías creadas usando la función levels().\n\ncolores <- c('blue', 'red', 'green', 'red', 'black', 'yellow','blue','blue')"
  },
  {
    "objectID": "guias/guia2.html#referencias",
    "href": "guias/guia2.html#referencias",
    "title": "Guía 2",
    "section": "Referencias",
    "text": "Referencias\n\nEstadística descriptiva:\n\nCap. 2 de Answering questions with data. Matthew J. C. Crump, Danielle J. Navarro, and Jeffrey Suzuki.\n\n\n\nVisualización de datos:\n\nCap. 2 de R for Data Science (2e). Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund.\nCap. 4 de Data Science. A First Introduction. Tiffany Timbers, Trevor Campbell, and Melissa Lee."
  },
  {
    "objectID": "guias/guia2.html#estadística-descriptiva",
    "href": "guias/guia2.html#estadística-descriptiva",
    "title": "Guía 2",
    "section": "Estadística descriptiva:",
    "text": "Estadística descriptiva:\n\nCap. 2 de Answering questions with data. Matthew J. C. Crump, Danielle J. Navarro, and Jeffrey Suzuki."
  },
  {
    "objectID": "guias/guia2.html#visualización-de-datos-1",
    "href": "guias/guia2.html#visualización-de-datos-1",
    "title": "Guía 2",
    "section": "Visualización de datos:",
    "text": "Visualización de datos:\n\nCap. 2 de R for Data Science (2e). Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund.\nCap. 4 de Data Science. A First Introduction. Tiffany Timbers, Trevor Campbell, and Melissa Lee."
  },
  {
    "objectID": "slides/clase3.html#datos",
    "href": "slides/clase3.html#datos",
    "title": "Laboratorio de datos",
    "section": "Datos:",
    "text": "Datos:\n\n\n\n\n\n\n\nNombre\n      ¿qué muestra?\n      objeto geométrico\n      nota\n    \n\n\nscatter (dispersión)\nrelación entre dos variables numéricas\ngeom_point()\n\n\n\nlínea\nrelación entre dos variables numéricas\ngeom_line()\nse usa cuando la variable del eje x tiene un orden (por ejemplo, tiempo)\n\n\nhistograma\ndistribución de una variable numérica\ngeom_histogram()\ncombinado con un faceteado muestra la distribución de una variable numérica desagregada por el valor de otra variable\n\n\nboxplot\ndistribución de una variable numérica (puede desagregarse por el valor de otra variable)\ngeom_boxplot()\n\n\n\nbarplot\ndistribución de una variable categórica\ngeom_bar() cuando ya no hecho el conteo, geom_col() cuando el conteo está hecho\nStacked, side-by-side, and faceted barplots show the joint distribution of 2 categorical variables"
  },
  {
    "objectID": "slides/clase3.html#tipos-de-variables",
    "href": "slides/clase3.html#tipos-de-variables",
    "title": "Laboratorio de datos",
    "section": "Tipos de variables",
    "text": "Tipos de variables\n\n\n\n\n\n\n\n  \n  \n\nNombre\n      ¿qué muestra?\n      objeto geométrico\n      nota\n    \n\n\nscatter (dispersión)\nrelación entre dos variables numéricas\ngeom_point()\n\n\n\nlínea\nrelación entre dos variables numéricas\ngeom_line()\nse usa cuando la variable del eje x tiene un orden (por ejemplo, tiempo)\n\n\nhistograma\ndistribución de una variable numérica\ngeom_histogram()\ncombinado con un faceteado muestra la distribución de una variable numérica desagregada por el valor de otra variable\n\n\nboxplot\ndistribución de una variable numérica (puede desagregarse por el valor de otra variable)\ngeom_boxplot()\n\n\n\nbarplot\ndistribución de una variable categórica\ngeom_bar() cuando ya no hecho el conteo, geom_col() cuando el conteo está hecho\nStacked, side-by-side, and faceted barplots show the joint distribution of 2 categorical variables"
  },
  {
    "objectID": "slides/clase3.html#geom_point",
    "href": "slides/clase3.html#geom_point",
    "title": "Laboratorio de datos",
    "section": "geom_point()",
    "text": "geom_point()\n\n\n\nggplot(data = penguins, \n       mapping = aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point() + \n  theme_classic()"
  },
  {
    "objectID": "slides/clase3.html#geom_point-1",
    "href": "slides/clase3.html#geom_point-1",
    "title": "Laboratorio de datos",
    "section": "geom_point()",
    "text": "geom_point()\n\nggplot(data = penguins, \n       mapping = aes(x = bill_length_mm, y = bill_depth_mm)) + \n  geom_point() + \n  theme_classic()"
  },
  {
    "objectID": "guias/guia3.html#estadística-descriptiva",
    "href": "guias/guia3.html#estadística-descriptiva",
    "title": "Guía 3: Análisis exploratorio de datos y visualización",
    "section": "Estadística descriptiva:",
    "text": "Estadística descriptiva:\n\nCap. 2 de Answering questions with data. Matthew J. C. Crump, Danielle J. Navarro, and Jeffrey Suzuki."
  },
  {
    "objectID": "guias/guia3.html#visualización-de-datos",
    "href": "guias/guia3.html#visualización-de-datos",
    "title": "Guía 3: Análisis exploratorio de datos y visualización",
    "section": "Visualización de datos:",
    "text": "Visualización de datos:\n\nCap. 2 de R for Data Science (2e). Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund.\nCap. 4 de Data Science. A First Introduction. Tiffany Timbers, Trevor Campbell, and Melissa Lee."
  },
  {
    "objectID": "guias/guia3.html",
    "href": "guias/guia3.html",
    "title": "Guía 3: Análisis exploratorio de datos y visualización",
    "section": "",
    "text": "1 Visualización\n1.1 ¿Qué tipo de gráfico usarían para contribuir a responder las preguntas planteadas en cada una de estas situaciones? Los tipos posibles son: histograma, bar plot, box plot, scatter plot y line plot.\n\nEn una encuesta, se pregunta por el máximo nivel educativo alcanzado por las personas (codificado por la variable “edu” que puede ser: “primario”, “secundario”, “universitario”). En el dataset, cada fila corresponde a un individuo y la columna de interés, “edu”. Se quiere entender la proporción de personas de cada nivel educativo que respondieron la encuesta.\nUn pediatra registra la altura de un bebe desde su nacimiento hasta cumplir un año y quiere graficar la evolución de la altura a lo largo de ese lapso.\nUn laboratorio de física midió en 1879 la velocidad de la luz 100 veces. No les da siempre igual por diversos motivos (errores de medición). Quieren ver cómo se distribuyen las mediciones.\nLas 100 mediciones del punto anterior corresponden a 5 experimentos de 20 mediciones cada uno. Ahora quieren visualizar variables de resumen de las mediciones desagregadas por experimento.\nA un grupo de 43 personas de Argentina se les preguntó quién creen que fue mejor jugador, Maradona o Messi. 20 respondieron que fue Maradona y 23 que fue Messi. Estos datos están volcados en un dataframe de dos columnas (“mejor” y “n”) por dos filas. Se quiere describir visualmente cuántas personas eligieron a cada jugador.\nPara investigar la relación entre las horas de sueño de una persona y el consumo de cafeína, se cuenta con un conjunto de datos que consta de respuestas de 100 personas a las siguientes preguntas: ¿cuántas horas duerme por la noche en promedio? ¿cuántos cafés toma por día en promedio?\n\n1.2 Poner en práctica las respuestas anteriores utilizando los siguientes datos. Es decir, crear un gráfico usando ggplot2. Piensen qué geom usarían en cada caso.\n\n# datos simulados del maximo nivel educativo de 100 personas\ndata.edu <- data.frame(id = 1:100, \n                       edu = sample(x = c(\"primario\",\"secundario\",\"universitario\"), \n                                    size = 100, \n                                    replace = T, \n                                    prob = c(0.1, 0.5, 0.4)))\n\n# datos de la preferencia por Maradona-Messi de 43 personas hipotéticas:\ndata.futbol <- data.frame(mejor = c(\"maradona\", \"messi\"),\n                          n     = c(20, 23))\n\n# datos de altura y mes de vida de un bebé.\ndata.alturas <- data.frame(mes = c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12),\n                           altura = c(50, 55, 57, 61, 62, 63, 64, 66, 68, 69, 71, 73, 75))\n\n# los datos del experimento que mide la velocidad de la luz estan en el data frame \n# \"morley\" que viene en R. ¿qué columnas tiene?\ndata.luz <- morley\n\n# datos de horas de sueño y consumo de café\ncafe = runif(100, min = 0, max = 3)\ndormir = rnorm(100, mean = 8) - cafe\ndata.cafe <- data.frame(cafe, dormir) \n\n1.3 Cargando el paquete ggplot2 tienen el data frame mpg (View(mpg)). Averiguar qué significan las variables corriendo ?mpg en la consola. Hacer un gráfico del consumo en hwy en función de la displ de los autos en el que cada observación (auto) está graficada con un triángulo rosa (Ayuda: buscar acá las especificaciones de ggplot2).\n1.4 ¿Por qué el siguiente código no resulta en un gráfico con puntos azules? Corregirlo para que funcione.\n\nggplot(mpg) + \n  geom_point(aes(x = displ, y = hwy, color = \"blue\"))\n\n1.5 ¿Qué pasa si uno mapea una “aesthetic()” a algo que no es una variable? Por ejemplo:\n\nggplot(mpg, aes(x=displ, y=hwy, fill = displ < 5)) + \n  geom_point(shape = 24, size = 4) + theme_classic()\n\n1.6 Reproducir el siguiente grafico y agregarle título, subtítulo, caption. Cambiarle el label del eje x y del eje y.\n\n\n\n\n\n1.7 Hacer un histograma del consumo de los autos en ciudad y otro del consumo en hwy.\n1.8 Hacer un boxplot del consumo discriminado por tracción. Es decir, 3 boxplots. ¿Cuál es la tracción que menos consume?\n1.9 Reproducir los siguientes gráficos (notar que la variable categórica que se usa para graficar es drv).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.10 ¿Por qué aparecen celdas vacías en este gráfico “facetado”?\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() +\n  theme_bw() + \n  facet_grid(drv~cyl)\n\n1.11 Leer ?facet_wrap. ¿Qué hacen los argumentos nrow y ncol? Explorar qué otras opciones existen para el controlar el aspecto del “facetado”? ¿Por qué facet_grid() no tiene como argumentos a nrow y ncol?\n1.12 Considerar el siguiente código para generar un gráfico “faceteado”:\n\nggplot(mpg, aes(x = displ, y = hwy)) + \n  geom_point() +\n  theme_bw() + \n  facet_wrap(~class, nrow = 2)\n\n\nGraficar la misma información pero mapeando la class en el color.\n¿Qué ventajas y desventajas tiene el “faceteado” frente al aesthetic de color? ¿En qué circunstancias usarían una forma o la otra?\n\n1.13 Comparar estas dos formas de entender la relación entre el tamaño del motor (displ) y la tracción del auto. ¿Qué hace el . y qué diferencia hay entre facet_grid(drv ~ .) y facet_grid(. ~ drv )? ¿Cuál de las dos formas facilita la comparación? ¿Qué les dice esto respecto de cuándo usar un faceteado sobre filas y sobre columnas?\n\nggplot(mpg, aes(x = displ)) + \n  geom_histogram() + \n  facet_grid(drv ~ .) +\n  theme_bw()\n\nggplot(mpg, aes(x = displ)) + \n  geom_histogram() + \n  facet_grid(. ~ drv) +\n  theme_bw()\n\n\n\n2. Análisis exploratorio\n2.1 Usando distintas estrategia de visualización, usar el dataset de pinguinos para explorar cuáles parecen ser las variables más importantes para predecir la masa corporal de los pinguinos. Reportar los gráficos que lo guian hacia esa conclusión.\n\n\nReferencias\n\nRecomendamos esta class de visualización de datos con ggplot2 de la Dra. Lucía Babino del Instituto de Cálculo.\nCap. 10-11 de R for Data Science (2e). Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund.\nCap. 4 de Data Science. A First Introduction. Tiffany Timbers, Trevor Campbell, and Melissa Lee."
  },
  {
    "objectID": "guias/guia4.html",
    "href": "guias/guia4.html",
    "title": "Guía 4: Transformación de datos",
    "section": "",
    "text": "1. Transformación de datos\nPara estos ejercicios, usar el dataset penguins del paquete palmerpenguins.\n1.1 Usar filter() para crear un subconjunto de datos que contenga sólo pinguinos de la isla Biscoe y que tengan un pico de 48 mm de largo o más.\n1.2 Crear otro dataset con la información de pinguinos Adelie machos que no hayan sido vistos en el año 2008.\n1.3 Del dataset penguins quedarse con todas las variables excepto year, sex y body_mass_g.\n1.4 Crear un subconjunto de los datos de penguins sólo con las obsevaciones de pinguinos machos con aletas (flipper) de más de 200 mm de largo y quedarse con todas las columnas que terminan con “mm”. (Ayuda: explorar cómo se usa la función ends_with() y sus parientes acá).\n1.5 Empezando con penguins, hacer un pipe (%>%) que:\n\nse quede sólo con las observaciones de la isla Dream.\nse quede con las variables species y todas las que empiece con bill.\n\n1.6 Convertir todas las variables que empiezan con bill a mayúsculas. (Ayuda: ?rename_with y toupper() )\n1.7 Empezando con penguins hacer lo siguiente con un único llamado a la función mutate():\n\nConvertir la variable species a character.\nCrear una nueva variable que tenga el peso en Kg.\nConvertir la variable island a minúscula.\n\n1.8 Empezando con penguins crear una tabla resumen que contenga para el largo mínimo y máximo de las aletas de los pinguinos Adelie, agrupados por isla.\n1.9 Empezando con penguins, agrupar los datos por especie y año, luego crear una tabla de resumen que contenga el ancho del pico (llamarla bill_depth_mean) y el largo del pico (llamarla bill_length_mean) para cada grupo\n1.10 Empezando con penguins, hacer una secuencia de operaciones %>% que:\n\nAgregue una nueva columna llamada bill_ratio que sea el cociente entre el largo y el ancho del pico.\nQuedarse sólo con las columnas species y bill_ratio.\nAgrupar los datos por especie.\nCrear una tabla de resumen que contenga el promedio de la variable bill_ratio por especie y que el nombre de la columna en la tabla sea bill_ratio_mean).\n\n1.11 Usar rename() para cambiarle el nombre a la variable body_mass_g y llamarla masa_corporal_g.\n1.12 Calcular la mediana de la masa corporal de los pinguinos de cada especie usando group_by y summarise().\n1.13 Empezando con penguins, escribir una secuencia de operaciones %>% que:\n\nExcluya a los pinguinos observados en la isla Biscoe.\nSólo se quede con las variables que están entre species y body_mass_g inclusive.\nRenombrar la variable species a especie_pinguino.\nAgrupar los datos por la variable especie_pinguino.\nEncontrar el valor medio de las variables que contienen el string “length”, separando por la especie del pinguino, y llamando a las columnas como las originales pero agregando “_mean” al final.\n\n1.14 Empezando con penguins, contar cuántas observaciones hay por especie, isla y año.\n1.15 Empezando con penguins, quedarse sólo con los pinguinos Adelie y gentoo penguins. Luego contar cuántos hay por cada especie y sexo.\n1.16 Agregar una nueva columna a la base de datos llamada peso_bin que contenga:\n\n“chico” si la masa corporal es menos que 4000 gramos.\n“grande” si la masa corporal es mayor que 4000 gramos.\n\n1.17 Empezando con penguins quedarse sólo con las observaciones correspondientes a pinguinos chinstrap. Luego, quedarse sólo con las variables flipper_length_mm y body_mass_g. Agregar una nueva columna llamada fm_ratio que contenga el cociente entre el largo de la aleta y el peso del pinguino. Luego quedarse solo con las observaciones que no tienen NA en ninguna columna (ayuda: ?drop_na()) y agregar otra columna llamada ratio_bin que contenga la palabra “alto” si fm_ratio es mayor o igual que 0.05 y “bajo” si el cociente es menor que 0.05).\n\n\n2. Exploración de datos\nPara resolver estos ejercicios usando lo que han aprendido de transformación, exploración y visualización de datos usando los paquetes de tidyverse.\n2.1 ¿Te parece que los pinguinos macho tienen más masa corporal que las hembras? Poner a prueba tu intiuición con visualizaciones y estadística descriptiva.\n2.2 ¿Te parece que pinguinos con pico más largo (bill_length_mm) tienen a su vez el pico más ancho (bill_depth_mm)? Poner a prueba esta intuición con visualizaciones y estadística descriptiva.\n2.3 En el 2.2 ¿da igual si consideran cada especie del pinguino por separado? ¿Qué tiene esto que ver con la paradoja de Simpson?\n2.4 Repetir 2.1 pero tomando un subconjunto aleatorio de \\(N\\) pinguinos (explorar diferentes números para \\(N\\)) (Ayuda: buscar ?sample_n()).\n\n\nReferencias\n\nRecomendamos esta clase de la Dra. Lucía Babino del Instituto de Cálculo.\ntutorial de dplyr.\nCap. 3 de Data Science. A First Introduction. Tiffany Timbers, Trevor Campbell, and Melissa Lee.\nCap. 4 de R for Data Science (2e). Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund."
  },
  {
    "objectID": "slides/clase4.html",
    "href": "slides/clase4.html",
    "title": "Clase 4 - Laboratorio de datos 2023",
    "section": "",
    "text": "En esta clase vamos a aprender a transformar datos usando funciones que vienen con el paquete dplyr, parte del tidyverse. Especialmente:\n\nfilter(): quedarse con las filas que satisfacen ciertas condiciones.\nselect(): quedarse o excluir algunas columnas del dataset.\nrelocate()`: renombrar columnas.\nrename()`: mover columnas de lugar.\nmutate(): crear una nueva variable (columna) operando con las demás.\ngroup_by() + summarize(): obtener medidas resumen de los datos por grupos.\nacross(): aplicar una función a varias columnas.\ncount(): contar rápidamente cuántas observaciones hay por grupo.\ncase_when(): una forma de hacer “if-else”.\n\nTambién vamos a ver cómo se contatenan estas funciones con el operador pipe %>%, del paquete magrittr del tidyverse.\nPara esto vamos a cargar los paquetes de tidyversey los datos de gapminder\n\nrequire(tidyverse)\nrequire(gapminder)\nd <- gapminder\nd\n\n\n\n  \n\n\n\n\n\n\n\nLa función filter permite quedarse con un subconjunto de observaciones que cumplen con una o más condiciones. Por ejemplo, si queremos quedarnos con las observaciones de Argentina, podemos hacer lo siguiente\n\nfilter(d, country == \"Argentina\")\nfilter(d, country == \"Argentina\" & year > 1980)\n\n\n\n\nSe usa para seleccionar columnas específicas de un data frame (útil cuando se quiere enfocar sólo en algunas variables). Vamos a seleccionar las variables country, lifeExp y gdpPercap de gapminder.\n\nselect(d, country, lifeExp, gdpPercap)\n\n\n\n\nSe usa para crear nuevas columnas (variables) que pueden ser funciones de las otras. Por ejemplo, agreguemos una columna que se llame lifeExp_group a partir de las observaciones anteriores:\n\nmutate(d, lifeExp_group = ifelse(lifeExp < 60, 'baja', 'alta'))\n\n\n\n\nSupongamos que queremos filtrar los datos de América, seleccionar las columnas country, year y gdpPercap y agregar una nueva variable que sea el siglo (siglo20 y siglo21). Hay varias opciones:\n\n# opción 1: pasos intermedios\n# opción 2: concatenar\n# opción 3: usar el operador %>% (pipe)\n\n\n\n\n\n\n\nAgrupar sirve para obtener información resumida por grupo. Por ejemplo, podemos agrupar los datos por continente:\n\nd %>% \n  group_by(continent)\n\n\n\n\nLa función count permite contar el número de observaciones en cada grupo después de que ocurrió la\n\nd %>% \n  group_by(continent) %>% \n  count()\n\n\n\n\nSummarize data by calculating summary statistics. Here, we find the average age by gender.\n\ndata %>% \n  group_by(gender) %>% \n  summarize(avg_age = mean(age))\n\n\n\n\n\n\n\nChanging column names can improve readability. We rename the ‘gender’ column to ‘sex’ in data.\n\ndata %>% \n  rename(sex = gender)\n\n\n\n\nReordering columns can be helpful. Let’s move the ‘age’ column before ‘name’ in data.\n\ndata %>% \n  relocate(age, .before = name)\n\n\n\n\nPerforming the same operation on multiple columns can be done with across. Let’s calculate the mean of numeric columns in data.\n\ndata %>% \n  summarize(across(where(is.numeric), mean))\n\n\n\n\nConditional transformations can be achieved using case_when. Let’s create a new column ‘status’ based on age.\n\ndata %>% \n  mutate(status = case_when(\n    age < 30 ~ 'Young',\n    age >= 30 & age < 60 ~ 'Adult',\n    age >= 60 ~ 'Senior'\n  ))\n\n\n\n\n\n\n\nPivoting data from long to wide format is useful for reshaping. We pivot data_long to a wider format.\n\ndata_long %>%\n  pivot_wider(names_from = key, values_from = value)\n\n\n\n\nConversely, pivoting data from wide to long format is done with pivot_longer. We pivot data_wide to a longer format.\n\ndata_wide %>%\n  pivot_longer(cols = -id, names_to = \"variable\", values_to = \"value\")\n\nThese are some of the essential operations in data manipulation using dplyr in R. Practice and experimentation are key to mastering these functions. Happy data wrangling!"
  },
  {
    "objectID": "guias/guia5.html",
    "href": "guias/guia5.html",
    "title": "Guía 5: Programación en R: funciones, iteraciones",
    "section": "",
    "text": "1. Unir data frames\nEn esta parte de la guía se utilizarán datos ficticios generados aleatoriamente para emular parte de la estructura de datos que podría haber en un sistema de información de una institución educativa. En dicho sistema hay una tabla (dfEstudiantes) con ciertos datos de las/os estudiantes (legajo, edad, carrera) y otra tabla (dfNotas) con las notas de los exámenes de Biología y de Matemática (legajo, nota, materia).\nEl siguiente código permite crear las dos tablas que se usarán en esta guía:\n\nlibrary(dplyr)\n\nset.seed(1010)\naux = rchisq(100, df=2)\n\ndfEstudiantes = tibble(legajo = paste0(\"LE_\",1:100), \n                       edad = as.integer((80-18) * aux/max(aux) + 18),\n                       carrera = sample(c(\"Ciencias Físicas\",\n                                          \"Ciencias Matemáticas\",\n                                          \"Ciencias de Datos\",\n                                          \"Paleontología\",\n                                          \"Ciencias Biológicas\",\n                                          \"Ciencias de la Atmósfera\",\n                                          \"Ciencias de la Computación\",\n                                          \"Ciencias Geológicas\",\n                                          \"Ciencias Químicas\",\n                                          \"Ciencia y Tecnología de Alimentos\",\n                                          \"Oceanografía\"),\n                                        100, replace = T))\n\ndfNotas = rbind(tibble(legajo = sample(paste0(\"LE_\",1:50),30),\n                       nota = as.integer(runif(30,min=2,max=10)),\n                       materia = \"Biología\"),\n                tibble(legajo = sample(paste0(\"LE_\",1:100),50),\n                       nota = as.integer(runif(50,min=2,max=10)),\n                       materia = \"Matemática\"))\n\n1.1 Cuál es la nota promedio por carrera de la materia Biología?\n1.2 Cuál es la cantidad de estudiantes por carrera que no rindió ninguno de los dos exámenes?\n1.3 Cuál es la edad promedio de los estudiantes que rindieron al menos uno de los dos exámenes? Tener en cuenta que un/a mismo/a estudiante puede haber rendido más de un examen. Revisar el uso de la función distinct().\n1.4 Generar un gráfico que permita visualizar la distribución de notas por grupo etario y materia, considerando los grupos etarios: [18, 21], (21,27] y [27, 80).\n\n\n2. Funciones\n2.1 Escribir una función que calcule el rango de un vector numérico. Comparar con la función range() de R.\n2.2 Escribir una función que calcule la media de un vector numérico. Comparar con la función mean() de R.\n2.3 Escribir una función que calcule la proporción de valores faltantes (NA) en un vector numérico.\n2.4 Modiicar la función de 2.3 para que reemplace los NA con un valor específico numérico (-1 por ejemplo).\n2.5 Crear una función que reemplace valores especificados en un vector numérico (por ejemplo los -1) con NA.\n2.6 Pensar qué operación realiza el siguiente script y transformarlo en una función. ¿Cuántos argumentos necesitaría? ¿Cómo la llamaría a la función?\n\nround(x / sum(x, na.rm = TRUE) * 100, 1)\nround(y / sum(y, na.rm = TRUE) * 100, 1)\nround(z / sum(z, na.rm = TRUE) * 100, 1)\n\n2.7 Escribir la función ambos_na() que toma dos vectores del mismo tamaño y devuelve los índices correspondientes a posiciones donde los dos vectores tienen NA. ¿Qué sucede con esta función si los vectores tienen distinto tamaño? Agregar una verificación y mensaje de texto que advierta que los vectores no tienen el mismo tamaño.\n2.8 Escribir una función que devuelva un objeto gráfico de ggplot2 que realice de forma incremental lo siguiente\n\nDibuje un scatterplot de la variable ´x´ e ´y´ de un dataset.\nAgregar una recta correspondiente al mejor ajuste lineal (sin mostrar el sombreado de margen de error).\nAgregue un título\n\n2.9 Pensar qué hace esta función y entendiendo su finalidad, sugerir un mejor nombre:\n\nf2 &lt;- function(lst, n) {\n  length(lst) &gt;= n\n}\n\n2.10 Si alguna de las funciones que escribiste en los ejercicios anteriores tenían nombres crípticos, cambiarlos por nombres más apropiados.\n2.11 Escribir una función que filtre un data frame para seleccionar filas donde una columna específica contiene valores faltantes.\n2.12 Escribir una función que calcule estadísticas resumidas (media, mediana, mínimo, máximo) para una columna numérica en un data frame.\n2.13 Ídem el anterior pero agrupando por grupo (es decir, uno de los argumentos de la función debe ser la variable por la que hay que agrupar).\n2.14 Escribir una función que genere un gráfico de dos variables numéricas de un data frame usando geom_hex(). Comprobar con un ejemplo.\n\n\n3. Iteraciones\n3.1 Utilice un while para encontrar la potencia menor de 2 que sea mayor que 1000.\n3.2 Escribe un while para calcular la suma de todos los números naturales positivos menores que 100 que sean múltiplos de 7.\n3.3 Crea un while para simular el crecimiento de una población. Comienza con 100 individuos y, cada año, la población se duplica. Calcula cuántos años se necesitan para que la población alcance los 1000.\n3.4 Utilice un bucle mientras para encontrar el número primo más grande menor que 100.\n\n\n4. Desafíos\n4.1 Escribir una función que simule N tiradas de un dado y devuelva la suma de los valores obtenidos. Repetir el proceso 10000 veces y hacer un histograma con los resultados obtenidos. Ayuda: cada tirada del dado corresponde a elegir uno de los siguientes números con igual probabilidad: {1, 2, 3, 4, 5, 6}.\nA- Usando la función sample() de R simule una tirada de un dado.\nB- Crear una función que realice la suma de los resultados de N dados. Evaluar la función en distintos valores de N.\n\nsuma_dados &lt;- function(N){\n  todos     &lt;- sample(___, ___, replace = ___)\n  respuesta &lt;- ___\n  return(___)\n}\n\nsuma_dados(___)\n\nC- Escribir un loop que repita el proceso anterior 10000 veces, guardando el resultado de cada ‘experimento’ en un vector.\nD- Haga un histograma de los resultados anteriores.\n4.2 En un grupo de N personas, ¿cuál es la probabilidad de que al menos dos personas cumplan años el mismo día?\nA- Simular las fechas de cumpleaños de N=50 personas y guardarlas en un vector.\n\nN &lt;- 50\ncumples &lt;- sample(___, N, replace = ___)\n\nB- Evaluar si hubo o no una coincidencia. ¿Qué hace la función unique()?\nC- Repetir el proceso anterior 10000 veces y contar todos los casos en los que hubo al menos 1 coincidencia\n\n# variable que va a contar las coincidencias\nn_coincidencias &lt;- 0\n\n# simula 10000 grupos de N=50 personas y verifica si hubo coincidencias o no\nNrep &lt;- 10000\nfor(i in 1:Nrep){\n  cumples &lt;- sample(seq(1,365,1), N, replace = TRUE)\n  if(length(unique(cumples)) &lt; N){\n    n_coincidencias &lt;- ___\n  } \n}\n\n# calcula la probabilidad estimada de coincidencias y la imprime en la consola\np_coincidencias &lt;- n_coincidencias / Nrep\nprint(p_coincidencias)\n\nD- Crear una función ‘pcumples’ que tenga dos inputs: el número de personas (N) y el número de repeticiones del experimento (Nrep). La salida de la función debe ser la probabilidad de tener al menos una coincidencia.\n\npcumples &lt;- function(N=50, Nrep=10000){\n  # 50 y 10000 son los valores por defecto de la función\n  ___\n  ___\n  return(___)\n}\n\nE- La función pbirthday() de R calcula la probabilidad de coincidencia en un grupo de N personas. Comparar el resultado anterior con el que se obtiene con la función pcumples que crearon en el ítem anterior.\nF- Hacer un gráfico que muestre la probabilidad de coincidencia en función del número de personas en el grupo. Puede usar la función pbirthday() o pcumples().\n\n# Define el vector con los tamaños de los grupos.\nN_vec &lt;- ___\n\n# ejecuta la función para cada elemento del vector anterior\nfor (i in 1:length(Nvec)){\n  p_c[___] &lt;- pbirthday(___)\n}\n\n# una forma equivalente de hacer el loop anterior es usando la función sapply\np_c[___] &lt;- sapply(___)\n\n# crea el gráfico\nggplot(____)\n\n4.3 Si en una votación entre dos candidatos, n votantes votan por A y m votantes votan por B (con n&gt;m) la probabilidad de A le vaya ganando a b a lo largo de todo el escrutinio es (n−m)/(n+m) . Nota: el que me presentó este problema es Pablo Groisman en Twitter. Pueden ver la demostración acá. En este ejercicio tienen que hacer simulaciones de escrutinios, evaluar si A le gana a B a lo largo de todo el escrutinio y comparar el resultado obtenido con el cálculo exacto.\nA- Crear un vector que contenga todos los votos, usando la notacion +1 para votos para el candidato A y -1 para el candidato B (¿por qué es conveniente esto?)\n\nn &lt;- 500 # numero de votos para A\nm &lt;- 400 # numero de votos para B\nvotos &lt;- c( ___, ___ )\n\nB- Un escrutinio es un posible orden en el que van apareciendo las boletas. Crear un escrutinio y evaluar si A se mantuvo siempre al frente.\n\n# realizar un escrutinio y evaluar si A se mantuvo al frente durante todo el escrutinio.\n# (puede servir usar la funcion cumsum. Que hace?)\nescrutinio &lt;- sample(___, n+m, replace = FALSE)\nresultado  &lt;- cumsum(___)\n# evaluar si A se mantuvo siempre al frente\nA_gana_siempre &lt;- ___ # TRUE si A gana siempre, FALSE si no.\n\nC- Repetir el proceso anterior 1000 veces y contar en cuantos escrutinios A se mantuvo al frente en todo el escrutinio\n\ncuenta &lt;- 0\nNrep   &lt;- 1000\nfor (i in 1:Nrep){\n  \n  escrutinio &lt;- sample(votos, n+m, replace = FALSE)\n  resultado  &lt;- cumsum(escrutinio)\n  if ( ___ ){\n    ___\n  }\n  \n}\n\np &lt;- ___\nprint(p)\nprint((n-m)/(n+m))\n\nD- Suponga ahora que 505 personas votaron por A y 495 personas por B. ¿Cuál es la probabilidad de que en el escrutinio vaya ganando B desde el comienzo hasta que se contaron 800 votos? Compare con el caso en que va ganando A, también hasta contar 800 votos.\n\nn &lt;- 505 # numero de votos para A\nm &lt;- 495 # numero de votos para B\nvotos &lt;- c( rep(1,n), rep(-1,m) )\n\n# cuentaA va a contar cuántas veces ocurre que A va ganando \n# hasta contar 800 votos\ncuentaA &lt;- 0  \ncuentaB &lt;- 0  # esta hace lo mismo para B\nNrep   &lt;- 10000\nfor (i in 1:Nrep){\n  \n  escrutinio &lt;- sample(votos, n+m, replace = FALSE)\n  resultado  &lt;- cumsum(escrutinio)\n  if ( ___ ){ \n    cuentaA &lt;- cuentaA + 1\n  }\n  if ( ___ ){  \n    cuentaB &lt;- cuentaB + 1\n  }\n  \n}\n\npA &lt;- cuentaA / Nrep\npB &lt;- cuentaB / Nrep\nprint(pA)\nprint(pB)\n\nE- En el 2017, en la provincia de Buenos Aires, la elección de senadores se definió por una diferencia pequeña entre los dos candidatos más votados. Sin embargo, durante el escrutinio provisorio, uno de ellos iba siempre al frente. ¿Qué suposición hicimos en las simulaciones que podría no ser cierta en un escrutinio real? 1\n4.4 Regla de la mayoría. Un modelo simple de propagación de opiniones supone que hay N personas que mantienen dos estados posibles de opinión: {+1, -1}. Inicialmente el número de personas en el estado +1 es n1&lt;N. Luego, en pasos sucesivos, 3 personas seleccionadas al azar interactúan de forma tal que adoptan la opinión mayoritaria entre los 3. Por ejemplo, si hay dos personas con opinión +1 y una con opinión -1, luego de la interacción, la opinión de los tres será +1.\nA- Crear el estado inicial de cada persona, usando un vector ‘Op’\n\nN  &lt;- 10   # numero total de personas\nn1 &lt;- 4    # numero de personas que inicialmente opinan +1\nOp &lt;- c( rep(1, n1), ___)\n\nB- Hacer una ronda de interacción. Esto es, elegir tres personas al azar, buscar la opinión mayoritaria y luego actualizar la opinión de cada uno.\n\nn_int     &lt;- sample(1:N, 3, replace = FALSE)\nOp[n_int] &lt;- ifelse( ___, 1, -1 )\n\nC- Repetir el proceso anterior hasta que se llegue a un consenso.\n\nOp       &lt;- ___\nconsenso &lt;- 0\nwhile( consenso != 1 ){\n  \n  n_int     &lt;- sample(1:N, 3, replace = FALSE)\n  Op[n_int] &lt;- ifelse( ___ )\n  \n  if (___ == 1){\n    consenso  &lt;- 1\n    Oconsenso &lt;- ___\n  }\n  \n}\n\nD- Crear una función que dado el número de personas (N), la fracción inicial que opina +1 (p), calcule la probabilidad de que el consenso se establezca en que todos opinen +1 (P1) realizando 100 experimentos simulados.\n\np_consenso &lt;- function(N, n1){\n  \n  output   &lt;- 0\n  \n  for (i in 1:100){\n    ___\n    ___\n    ___\n\n    if (Oconsenso == 1){\n      output &lt;- output + 1\n    }\n    \n  }\n  \n  return(output/100)\n}\n\nE- Graficar P1 en función de p para los siguientes valores de n1 = {1, 2, 3, …, 10}.\n4.5 Problema de Monty Hall. Un participante de un concurso tiene que elegir entre tres puertas. Detrás de una de ellas hay un premio. Al elegir una puerta, el conductor del concurso le señala cuál de las otras dos puertas seguro no tiene el premio. El participante tiene la opción de quedarse con su opción inicial o cambiar a la otra puerta. ¿Qué le conviene? Calcular la probabilidad de éxito, comparando simulaciones en las que el participante elige quedarse y otras en las que decide cambiar.\n\n\nReferencias\nPara la parte 1:\n\nCap. 20 de R for Data Science (2e), de Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund.\n\nPara el resto:\n\nCap. 26-27 de R for Data Science (2e), de Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund.\nCap. 11 de Hands-On Programming with R, de Garrett Grolemund.\nSobre el ejercicio 4.3: Si quieren saber qué pasó ese día: Antenucci, P., Mascioto, J. M., & Page, M. (2017). PASO 2017 en la provincia de Buenos Aires: el recuento provisorio explicado. Revista SAAP. Publicación de Ciencia Política de la Sociedad Argentina de Análisis Político, 11(2), 341-364."
  },
  {
    "objectID": "guias/guia5-temp.html",
    "href": "guias/guia5-temp.html",
    "title": "Guía 5: Programación en R: funciones, iteraciones",
    "section": "",
    "text": "1. Unir data frames\nEn esta parte de la guía se utilizarán datos ficticios generados aleatoriamente para emular parte de la estructura de datos que podría haber en un sistema de información de una institución educativa. En dicho sistema hay una tabla (dfEstudiantes) con ciertos datos de las/os estudiantes (legajo, edad, carrera) y otra tabla (dfNotas) con las notas de los exámenes de Biología y de Matemática (legajo, nota, materia).\nEl siguiente código permite crear las dos tablas que se usarán en esta guía:\n\nlibrary(dplyr)\n\nset.seed(1010)\naux = rchisq(100, df=2)\n\ndfEstudiantes = tibble(legajo = paste0(\"LE_\",1:100), \n                       edad = as.integer((80-18) * aux/max(aux) + 18),\n                       carrera = sample(c(\"Ciencias Físicas\",\n                                          \"Ciencias Matemáticas\",\n                                          \"Ciencias de Datos\",\n                                          \"Paleontología\",\n                                          \"Ciencias Biológicas\",\n                                          \"Ciencias de la Atmósfera\",\n                                          \"Ciencias de la Computación\",\n                                          \"Ciencias Geológicas\",\n                                          \"Ciencias Químicas\",\n                                          \"Ciencia y Tecnología de Alimentos\",\n                                          \"Oceanografía\"),\n                                        100, replace = T))\n\ndfNotas = rbind(tibble(legajo = sample(paste0(\"LE_\",1:50),30),\n                       nota = as.integer(runif(30,min=2,max=10)),\n                       materia = \"Biología\"),\n                tibble(legajo = sample(paste0(\"LE_\",1:100),50),\n                       nota = as.integer(runif(50,min=2,max=10)),\n                       materia = \"Matemática\"))\n\n1.1 Cuál es la nota promedio por carrera de la materia Biología?\n1.2 Cuál es la cantidad de estudiantes por carrera que no rindió ninguno de los dos exámenes?\n1.3 Cuál es la edad promedio de los estudiantes que rindieron al menos uno de los dos exámenes? Tener en cuenta que un/a mismo/a estudiante puede haber rendido más de un examen. Revisar el uso de la función distinct().\n1.4 Generar un gráfico que permita visualizar la distribución de notas por grupo etario y materia, considerando los grupos etarios: [18, 21], (21,27] y [27, 80).\n\n\n2. Funciones\n2.1 Escribir una función que calcule el rango de un vector numérico. Comparar con la función range() de R.\n2.2 Escribir una función que calcule la media de un vector numérico. Comparar con la función mean() de R.\n2.3 Escribir una función que calcule la proporción de valores faltantes (NA) en un vector numérico.\n2.4 Modiicar la función de 2.3 para que reemplace los NA con un valor específico numérico (-1 por ejemplo).\n2.5 Crear una función que reemplace valores especificados en un vector numérico (por ejemplo los -1) con NA.\n2.6 Pensar qué operación realiza el siguiente script y transformarlo en una función. ¿Cuántos argumentos necesitaría? ¿Cómo la llamaría a la función?\n\nround(x / sum(x, na.rm = TRUE) * 100, 1)\nround(y / sum(y, na.rm = TRUE) * 100, 1)\nround(z / sum(z, na.rm = TRUE) * 100, 1)\n\n2.7 Escribir la función ambos_na() que toma dos vectores del mismo tamaño y devuelve los índices correspondientes a posiciones donde los dos vectores tienen NA. ¿Qué sucede con esta función si los vectores tienen distinto tamaño? Agregar una verificación y mensaje de texto que advierta que los vectores no tienen el mismo tamaño.\n2.8 Escribir una función que devuelva un objeto gráfico de ggplot2 que realice de forma incremental lo siguiente\n\nDibuje un scatterplot de la variable ´x´ e ´y´ de un dataset.\nAgregar una recta correspondiente al mejor ajuste lineal (sin mostrar el sombreado de margen de error).\nAgregue un título\n\n2.9 Pensar qué hace esta función y entendiendo su finalidad, sugerir un mejor nombre:\n\nf2 <- function(lst, n) {\n  length(lst) >= n\n}\n\n2.10 Si alguna de las funciones que escribiste en los ejercicios anteriores tenían nombres crípticos, cambiarlos por nombres más apropiados.\n2.11 Escribir una función que filtre un data frame para seleccionar filas donde una columna específica contiene valores faltantes.\n2.12 Escribir una función que cuente el número de filas de un data frame donde una columna específica cumple una condición determinada.\n2.13 Escribir una función que calcule estadísticas resumidas (media, mediana, mínimo, máximo) para una columna numérica en un data frame.\n2.14 Escribir una función que calcule la proporción de filas de un data frame que cumplen una condición específica.\n2.15 Escribir una función que genere un gráfico de dos variables numéricas de un data frame usando geom_hex(). Comprobar con un ejemplo.\n\n\n3. Iteraciones\n3.1 Utilice un while para encontrar la potencia menor de 2 que sea mayor que 1000.\n3.2 Escribe un while para calcular la suma de todos los números naturales positivos menores que 100 que sean múltiplos de 7.\n3.3 Crea un while para simular el crecimiento de una población. Comienza con 100 individuos y, cada año, la población se duplica. Calcula cuántos años se necesitan para que la población alcance los 1000.\n3.4 Utilice un bucle mientras para encontrar el número primo más grande menor que 100.\n\n\n4. Desafíos\n4.1 Escribir una función que simule N tiradas de un dado y devuelva la suma de los valores obtenidos. Repetir el proceso 10000 veces y hacer un histograma con los resultados obtenidos. Ayuda: cada tirada del dado corresponde a elegir uno de los siguientes números con igual probabilidad: {1, 2, 3, 4, 5, 6}.\nA- Usando la función sample() de R simule una tirada de un dado.\nB- Crear una función que realice la suma de los resultados de N dados. Evaluar la función en distintos valores de N.\n\nsuma_dados <- function(N){\n  todos     <- sample(___, ___, replace = ___)\n  respuesta <- ___\n  return(___)\n}\n\nsuma_dados(___)\n\nC- Escribir un loop que repita el proceso anterior 10000 veces, guardando el resultado de cada ‘experimento’ en un vector.\nD- Haga un histograma de los resultados anteriores.\n4.2 En un grupo de N personas, ¿cuál es la probabilidad de que al menos dos personas cumplan años el mismo día?\nA- Simular las fechas de cumpleaños de N=50 personas y guardarlas en un vector.\n\nN <- 50\ncumples <- sample(___, N, replace = ___)\n\nB- Evaluar si hubo o no una coincidencia. ¿Qué hace la función unique()?\nC- Repetir el proceso anterior 10000 veces y contar todos los casos en los que hubo al menos 1 coincidencia\n\n# variable que va a contar las coincidencias\nn_coincidencias <- 0\n\n# simula 10000 grupos de N=50 personas y verifica si hubo coincidencias o no\nNrep <- 10000\nfor(i in 1:Nrep){\n  cumples <- sample(seq(1,365,1), N, replace = TRUE)\n  if(length(unique(cumples)) < N){\n    n_coincidencias <- ___\n  } \n}\n\n# calcula la probabilidad estimada de coincidencias y la imprime en la consola\np_coincidencias <- n_coincidencias / Nrep\nprint(p_coincidencias)\n\nD- Crear una función ‘pcumples’ que tenga dos inputs: el número de personas (N) y el número de repeticiones del experimento (Nrep). La salida de la función debe ser la probabilidad de tener al menos una coincidencia.\n\npcumples <- function(N=50, Nrep=10000){\n  # 50 y 10000 son los valores por defecto de la función\n  ___\n  ___\n  return(___)\n}\n\nE- La función pbirthday() de R calcula la probabilidad de coincidencia en un grupo de N personas. Comparar el resultado anterior con el que se obtiene con la función pcumples que crearon en el ítem anterior.\nF- Hacer un gráfico que muestre la probabilidad de coincidencia en función del número de personas en el grupo. Puede usar la función pbirthday() o pcumples().\n\n# Define el vector con los tamaños de los grupos.\nN_vec <- ___\n\n# ejecuta la función para cada elemento del vector anterior\nfor (i in 1:length(Nvec)){\n  p_c[___] <- pbirthday(___)\n}\n\n# una forma equivalente de hacer el loop anterior es usando la función sapply\np_c[___] <- sapply(___)\n\n# crea el gráfico\nggplot(____)\n\n4.3 Si en una votación entre dos candidatos, n votantes votan por A y m votantes votan por B (con n>m) la probabilidad de A le vaya ganando a b a lo largo de todo el escrutinio es (n−m)/(n+m) . Nota: el que me presentó este problema es Pablo Groisman en Twitter. Pueden ver la demostración acá. En este ejercicio tienen que hacer simulaciones de escrutinios, evaluar si A le gana a B a lo largo de todo el escrutinio y comparar el resultado obtenido con el cálculo exacto.\nA- Crear un vector que contenga todos los votos, usando la notacion +1 para votos para el candidato A y -1 para el candidato B (¿por qué es conveniente esto?)\n\nn <- 500 # numero de votos para A\nm <- 400 # numero de votos para B\nvotos <- c( ___, ___ )\n\nB- Un escrutinio es un posible orden en el que van apareciendo las boletas. Crear un escrutinio y evaluar si A se mantuvo siempre al frente.\n\n# realizar un escrutinio y evaluar si A se mantuvo al frente durante todo el escrutinio.\n# (puede servir usar la funcion cumsum. Que hace?)\nescrutinio <- sample(___, n+m, replace = FALSE)\nresultado  <- cumsum(___)\n# evaluar si A se mantuvo siempre al frente\nA_gana_siempre <- ___ # TRUE si A gana siempre, FALSE si no.\n\nC- Repetir el proceso anterior 1000 veces y contar en cuantos escrutinios A se mantuvo al frente en todo el escrutinio\n\ncuenta <- 0\nNrep   <- 1000\nfor (i in 1:Nrep){\n  \n  escrutinio <- sample(votos, n+m, replace = FALSE)\n  resultado  <- cumsum(escrutinio)\n  if ( ___ ){\n    ___\n  }\n  \n}\n\np <- ___\nprint(p)\nprint((n-m)/(n+m))\n\nD- Suponga ahora que 505 personas votaron por A y 495 personas por B. ¿Cuál es la probabilidad de que en el escrutinio vaya ganando B desde el comienzo hasta que se contaron 800 votos? Compare con el caso en que va ganando A, también hasta contar 800 votos.\n\nn <- 505 # numero de votos para A\nm <- 495 # numero de votos para B\nvotos <- c( rep(1,n), rep(-1,m) )\n\n# cuentaA va a contar cuántas veces ocurre que A va ganando \n# hasta contar 800 votos\ncuentaA <- 0  \ncuentaB <- 0  # esta hace lo mismo para B\nNrep   <- 10000\nfor (i in 1:Nrep){\n  \n  escrutinio <- sample(votos, n+m, replace = FALSE)\n  resultado  <- cumsum(escrutinio)\n  if ( ___ ){ \n    cuentaA <- cuentaA + 1\n  }\n  if ( ___ ){  \n    cuentaB <- cuentaB + 1\n  }\n  \n}\n\npA <- cuentaA / Nrep\npB <- cuentaB / Nrep\nprint(pA)\nprint(pB)\n\nE- En el 2017, en la provincia de Buenos Aires, la elección de senadores se definió por una diferencia pequeña entre los dos candidatos más votados. Sin embargo, durante el escrutinio provisorio, uno de ellos iba siempre al frente. ¿Qué suposición hicimos en las simulaciones que podría no ser cierta en un escrutinio real? 1\n4.4 Regla de la mayoría. Un modelo simple de propagación de opiniones supone que hay N personas que mantienen dos estados posibles de opinión: {+1, -1}. Inicialmente el número de personas en el estado +1 es n1<N. Luego, en pasos sucesivos, 3 personas seleccionadas al azar interactúan de forma tal que adoptan la opinión mayoritaria entre los 3. Por ejemplo, si hay dos personas con opinión +1 y una con opinión -1, luego de la interacción, la opinión de los tres será +1.\nA- Crear el estado inicial de cada persona, usando un vector ‘Op’\n\nN  <- 10   # numero total de personas\nn1 <- 4    # numero de personas que inicialmente opinan +1\nOp <- c( rep(1, n1), ___)\n\nB- Hacer una ronda de interacción. Esto es, elegir tres personas al azar, buscar la opinión mayoritaria y luego actualizar la opinión de cada uno.\n\nn_int     <- sample(1:N, 3, replace = FALSE)\nOp[n_int] <- ifelse( ___, 1, -1 )\n\nC- Repetir el proceso anterior hasta que se llegue a un consenso.\n\nOp       <- ___\nconsenso <- 0\nwhile( consenso != 1 ){\n  \n  n_int     <- sample(1:N, 3, replace = FALSE)\n  Op[n_int] <- ifelse( ___ )\n  \n  if (___ == 1){\n    consenso  <- 1\n    Oconsenso <- ___\n  }\n  \n}\n\nD- Crear una función que dado el número de personas (N), la fracción inicial que opina +1 (p), calcule la probabilidad de que el consenso se establezca en que todos opinen +1 (P1) realizando 100 experimentos simulados.\n\np_consenso <- function(N, n1){\n  \n  output   <- 0\n  \n  for (i in 1:100){\n    ___\n    ___\n    ___\n\n    if (Oconsenso == 1){\n      output <- output + 1\n    }\n    \n  }\n  \n  return(output/100)\n}\n\nE- Graficar P1 en función de p para los siguientes valores de n1 = {1, 2, 3, …, 10}.\n4.5 Problema de Monty Hall. Un participante de un concurso tiene que elegir entre tres puertas. Detrás de una de ellas hay un premio. Al elegir una puerta, el conductor del concurso le señala cuál de las otras dos puertas seguro no tiene el premio. El participante tiene la opción de quedarse con su opción inicial o cambiar a la otra puerta. ¿Qué le conviene? Calcular la probabilidad de éxito, comparando simulaciones en las que el participante elige quedarse y otras en las que decide cambiar.\n\n\nReferencias\nPara la parte 1:\n\nCap. 20 de R for Data Science (2e), de Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund.\n\nPara el resto:\n\nCap. 26-27 de R for Data Science (2e), de Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund.\nCap. 11 de Hands-On Programming with R, de Garrett Grolemund.\nSobre el ejercicio 4.3: Si quieren saber qué pasó ese día: Antenucci, P., Mascioto, J. M., & Page, M. (2017). PASO 2017 en la provincia de Buenos Aires: el recuento provisorio explicado. Revista SAAP. Publicación de Ciencia Política de la Sociedad Argentina de Análisis Político, 11(2), 341-364."
  },
  {
    "objectID": "tps/TP1.html#dataset-de-uso-de-ecobici",
    "href": "tps/TP1.html#dataset-de-uso-de-ecobici",
    "title": "TP-1",
    "section": "Dataset de uso de EcoBici",
    "text": "Dataset de uso de EcoBici\nEl dataset de uso del sistema Ecobici de la Ciudad de Buenos Aires está disponible acá. En particular, vamos a trabajar con datos del año 2022. El dataset que está en la página tiene casi 3 millones de registros, pero para este TP preparamos un dataset reducido de 10000 observaciones. Ese dataset reducido se encuentra acá."
  },
  {
    "objectID": "tps/TP1.html#dataset-de-clima",
    "href": "tps/TP1.html#dataset-de-clima",
    "title": "TP-1",
    "section": "Dataset de clima",
    "text": "Dataset de clima\nImporten datos meteorológicos y climáticos de MeteoStat de esta página. En particular, consideren datos de la estación meteorológica de Aeroparque (ID 87582), desde el 1ro de enero de 2022 hasta el 31 de diciembre de 2022."
  },
  {
    "objectID": "tps/TP1.html",
    "href": "tps/TP1.html",
    "title": "TP-1",
    "section": "",
    "text": "El objetivo de este TP es que apliquen todo lo que aprendieron hasta ahora de decripción, visualización, exploración y manipulación de datos al análisis de dos datasets. Los dos son datasets públicos, uno contiene el registro de usos de bicicletas públicas de CABA y el otro datos climáticos diarios."
  },
  {
    "objectID": "tps/TP1.html#importación-y-preprocesado-de-datos-en-r",
    "href": "tps/TP1.html#importación-y-preprocesado-de-datos-en-r",
    "title": "TP-1",
    "section": "Importación y preprocesado de datos en R",
    "text": "Importación y preprocesado de datos en R\nEn primer lugar seleccionar solo los viajes de entre 5 minutos y 1 hora de duración. Luego reconozcan qué significa cada variable. En la página donde está el dataset original encontrarán parte de esta información. Verifiquen que las variables tienen sentido, que tengan datos para todos los días del 2023, piensen en qué unidades se miden las variables numéricas, etc."
  },
  {
    "objectID": "tps/TP1.html#importación-y-preprocesado-de-datos-en-r-1",
    "href": "tps/TP1.html#importación-y-preprocesado-de-datos-en-r-1",
    "title": "TP-1",
    "section": "Importación y preprocesado de datos en R",
    "text": "Importación y preprocesado de datos en R\nDescarguen ese dataset en formato csv e importen los datos en R. Verifiquen que tienen datos de todos los días del 2023. ¿Qué representa cada variable?"
  },
  {
    "objectID": "guias/guia6.html",
    "href": "guias/guia6.html",
    "title": "Guía 6: Modelo lineal",
    "section": "",
    "text": "1.1 Cargar la librería palmerpenguins. Usando el dataset penguins y borrando las observaciones que tengan algún NA responder estas preguntas.\n1.2 Realizar un gráfico de dispersión que muestre la relación entre el ancho y el largo del pico de los pinguinos de la especie Adelie (columnas bill_depth_mm y bill_length_mm).\n1.3 Escribir la ecuación del modelo de regresión lineal simple que tenga como variable respuesta el largo del pico y como explicativa al ancho (usar lm() para calcular los coeficientes del modelo)\n\\[\n\\hat{\\text{largo}} =  \\text{??}  + \\text{??} \\times \\text{ancho}\n\\]\n1.4 ¿Qué unidades tienen la ordenada al origen y la pendiente? ¿Cómo se interpretan los valores estimados de la ordenada al origen y la pendiente?\n1.5 ¿Cuál es el error cuadrático medio del modelo? ¿Cuál es el coeficiente de determinación (\\(R^2\\))? Programar una función que calcule el error cuadrático medio y \\(R^2\\).\n1.6 Suponga que se encuentra un pinguino de la especie Adelie que tiene un pico de 2 cm de ancho. El dato del largo del pico se perdió. Usando el modelo lineal simple, ¿qué valor de largo de pico tendría ese pinguino? Si se encuentra un pinguino bebé con un pico de 5mm de ancho, ¿sería adecuado usar este modelo para conocer el largo del pico dado su ancho?\n1.7 Repetir 1.3 para los pinguinos de las otras 3 especies.\n1.8 Reproducir el gráfico que se muestra abajo usando geom_smooth(method=\"lm\", se = F) y luego, “a mano”, usando los resultados de 1.7 y geom_abline().\n\n\n\n\n\n1.9 Sólo para los pinguinos de la especie Adelie, definir una nueva variable que sea el ancho del pico centrado respecto al ancho promedio. Es decir, para cada pinguino \\(i\\):\n\\[\n\\text{ancho.cen}_i = \\text{ancho}_i - &lt;\\text{ancho}&gt;\n\\]\ndonde \\(&lt;\\text{ancho}&gt;\\) es el ancho promedio del pico.\nLuego repetir 1.3 para este modelo. Es decir, reemplazar los “??” por los estimadores de mínimos cuadrados.\n\\[\n\\hat{\\text{largo}} =  \\text{??}  + \\text{??} \\times \\text{ancho.cen}\n\\]\n1.10 ¿Qué interpretaición tienen ahora la ordenada al origen y la pendiente del modelo? Discutir las ventajas y desventajas de usar \\(\\text{ancho.cen}\\) o \\(\\text{ancho}\\).\n1.11 Calcular el coeficiente de determinación para este nuevo modelo. ¿Es igual o diferente al calculado en 1.5? Explicar."
  },
  {
    "objectID": "guias/guia6.html#ejercicio-1",
    "href": "guias/guia6.html#ejercicio-1",
    "title": "Guía 6: Modelo lineal",
    "section": "",
    "text": "1.1 Cargar la librería palmerpenguins. Usando el dataset penguins y borrando las observaciones que tengan algún NA responder estas preguntas.\n1.2 Realizar un gráfico de dispersión que muestre la relación entre el ancho y el largo del pico de los pinguinos de la especie Adelie (columnas bill_depth_mm y bill_length_mm).\n1.3 Escribir la ecuación del modelo de regresión lineal simple que tenga como variable respuesta el largo del pico y como explicativa al ancho (usar lm() para calcular los coeficientes del modelo)\n\\[\n\\hat{\\text{largo}} =  \\text{??}  + \\text{??} \\times \\text{ancho}\n\\]\n1.4 ¿Qué unidades tienen la ordenada al origen y la pendiente? ¿Cómo se interpretan los valores estimados de la ordenada al origen y la pendiente?\n1.5 ¿Cuál es el error cuadrático medio del modelo? ¿Cuál es el coeficiente de determinación (\\(R^2\\))? Programar una función que calcule el error cuadrático medio y \\(R^2\\).\n1.6 Suponga que se encuentra un pinguino de la especie Adelie que tiene un pico de 2 cm de ancho. El dato del largo del pico se perdió. Usando el modelo lineal simple, ¿qué valor de largo de pico tendría ese pinguino? Si se encuentra un pinguino bebé con un pico de 5mm de ancho, ¿sería adecuado usar este modelo para conocer el largo del pico dado su ancho?\n1.7 Repetir 1.3 para los pinguinos de las otras 3 especies.\n1.8 Reproducir el gráfico que se muestra abajo usando geom_smooth(method=\"lm\", se = F) y luego, “a mano”, usando los resultados de 1.7 y geom_abline().\n\n\n\n\n\n1.9 Sólo para los pinguinos de la especie Adelie, definir una nueva variable que sea el ancho del pico centrado respecto al ancho promedio. Es decir, para cada pinguino \\(i\\):\n\\[\n\\text{ancho.cen}_i = \\text{ancho}_i - &lt;\\text{ancho}&gt;\n\\]\ndonde \\(&lt;\\text{ancho}&gt;\\) es el ancho promedio del pico.\nLuego repetir 1.3 para este modelo. Es decir, reemplazar los “??” por los estimadores de mínimos cuadrados.\n\\[\n\\hat{\\text{largo}} =  \\text{??}  + \\text{??} \\times \\text{ancho.cen}\n\\]\n1.10 ¿Qué interpretaición tienen ahora la ordenada al origen y la pendiente del modelo? Discutir las ventajas y desventajas de usar \\(\\text{ancho.cen}\\) o \\(\\text{ancho}\\).\n1.11 Calcular el coeficiente de determinación para este nuevo modelo. ¿Es igual o diferente al calculado en 1.5? Explicar."
  },
  {
    "objectID": "guias/guia6.html#ejercicio-2",
    "href": "guias/guia6.html#ejercicio-2",
    "title": "Guía 6: Modelo lineal",
    "section": "Ejercicio 2",
    "text": "Ejercicio 2\n2.1 Utilizando la librería mtcars incluida en R-base, que contiene datos sobre automóviles, crear un gráfico para visualizar la relación entre la potencia del motor (columna hp) y la eficiencia en millas por galón (columna mpg). ¿Qué patrón se observa?\n2.2 Realiza una regresión lineal simple para predecir la eficiencia en millas por galón en función de la potencia del motor, ¿Cuál es el valor del coeficiente de determinación (\\(R^2\\))?\n2.3 Discutir si parece adecuado un modelo lineal para describir esta relación."
  },
  {
    "objectID": "guias/guia6.html#ejercicio-3",
    "href": "guias/guia6.html#ejercicio-3",
    "title": "Guía 6: Modelo lineal",
    "section": "Ejercicio 3",
    "text": "Ejercicio 3\n3.1 Cargar el conjunto de datos iris, incluida en R-base, que contiene información sobre especies de flores y sus características. Intenta realizar una regresión lineal simple para predecir la longitud del sépalo (columna Sepal.Length) en función del ancho del sépalo (columna Sepal.Width). ¿Cuál es el valor del coeficiente de determinación (\\(R^2\\))?"
  },
  {
    "objectID": "guias/guia6.html#ejercicio-4",
    "href": "guias/guia6.html#ejercicio-4",
    "title": "Guía 6: Modelo lineal",
    "section": "Ejercicio 4",
    "text": "Ejercicio 4\n4.1 Cargar la librería gapminder. Seleccionar datos de un año particular y realizar un gráfico de dispersión que muestre la relación entre el PIB per cápita (columna gdpPercap) y la esperanza de vida (columna lifeExp).\n4.2 Realizar una regresión lineal simple para predecir la esperanza de vida en función del PBI per cápita para 1997 en el continente americano.\n4.3 Discutir si el modelo es adecuado para describir esta relación.\n4.4 Calcular el error estándar de la estimación (SEE) para evaluar la precisión del modelo de regresión.\n4.5 Repetir 4.2 para un modelo pero utilizando como variable respuesta el logaritmo de la esperanza de vida y como variable explicativa el logaritmo del PBI per capita. Discutir la conveniencia de usar el logaritmo de las variables."
  }
]